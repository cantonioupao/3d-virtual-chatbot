{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f50QSSK1IKbT"
      },
      "source": [
        "# Neural rendering optimization: Fit FLAME mesh for improved DECA results\n",
        "\n",
        "Contents:\n",
        "\n",
        "\n",
        "-    Pytorch 3D installation, FLAME and rendering examples;\n",
        "-   Get image pairs, of face ground truth image and render prediction (DECA output);\n",
        "-   Rendering and optimising/training FLAME for better single subject rendering (improving DECA results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFHf97nDwV0A"
      },
      "source": [
        "## Install all dependencies/requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp37N2qpqcbR"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DPLUi7MqWeG",
        "outputId": "55f6d913-7f74-4d8c-8b2d-b07e963fbf88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIxi6ou1qv6v"
      },
      "source": [
        "### Installations (Rest)\n",
        "# After running this cell, restart runtime!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o7lSp57cq31b",
        "outputId": "c6741ddf-d204-4b26-cad7-e603cf004abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chumpy\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from chumpy) (1.4.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from chumpy) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.13.0->chumpy) (1.21.6)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58285 sha256=331c41f845c5993c2665ad977df99e5d38d097475a7eb8fb3a1df6890d9874d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/68/de/5e0c5d77e573e8c150e69e07a25035e6b6a04952d6e1814dbc\n",
            "Successfully built chumpy\n",
            "Installing collected packages: chumpy\n",
            "Successfully installed chumpy-0.70\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facenet_pytorch\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.12.0+cu113)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (4.2.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.11.0+cu113)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting backgroundremover\n",
            "  Downloading backgroundremover-0.1.9.tar.gz (15 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting idna>=3.2\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (4.64.0)\n",
            "Collecting more-itertools==8.7.0\n",
            "  Downloading more_itertools-8.7.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting Pillow==8.1.1\n",
            "  Downloading Pillow-8.1.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 15.5 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting moviepy==1.0.3\n",
            "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
            "\u001b[K     |████████████████████████████████| 388 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (1.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (0.18.3)\n",
            "Collecting waitress>=1.4.4\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting filetype>=1.0.7\n",
            "  Downloading filetype-1.0.13-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (0.12.0+cu113)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 69.0 MB/s \n",
            "\u001b[?25hCollecting hsh>=1.1.0\n",
            "  Downloading hsh-1.1.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: gdown>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (1.11.0+cu113)\n",
            "Collecting requests>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (1.21.6)\n",
            "Collecting pymatting>=1.1.1\n",
            "  Downloading PyMatting-1.1.5-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.5.30 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (2.0.12)\n",
            "Requirement already satisfied: filelock>=3.0.12 in /usr/local/lib/python3.7/dist-packages (from backgroundremover) (3.7.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.3->backgroundremover) (4.4.2)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.13.0->backgroundremover) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.13.0->backgroundremover) (2.23.0)\n",
            "Collecting commandlines\n",
            "  Downloading commandlines-0.4.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.19.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 52.2 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.19.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 50.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.19.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 56.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.18.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 47.3 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.17.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 46.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.16.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 31.2 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.5 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.14.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.2 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.14.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 54.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.13.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.5 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.13.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.5 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.13.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.1 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.13.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 45.8 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.13.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.7 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 43.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.12.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.3 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.11.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 57.0 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.11.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.5 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.10.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 58.2 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.10.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 42.9 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.10.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.3 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.10.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.1 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.10.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.7 MB/s \n",
            "\u001b[?25h  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 17.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.7/dist-packages (from pymatting>=1.1.1->backgroundremover) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba!=0.49.0->pymatting>=1.1.1->backgroundremover) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba!=0.49.0->pymatting>=1.1.1->backgroundremover) (0.34.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->backgroundremover) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->backgroundremover) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->backgroundremover) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->backgroundremover) (1.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->backgroundremover) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->backgroundremover) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->backgroundremover) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->backgroundremover) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->backgroundremover) (4.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python->backgroundremover) (0.16.0)\n",
            "Building wheels for collected packages: backgroundremover, moviepy\n",
            "  Building wheel for backgroundremover (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for backgroundremover: filename=backgroundremover-0.1.9-py3-none-any.whl size=18016 sha256=254cca6574e409ca814ff1961a8942189a7709f583a1423c35921e43369b0e64\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/6b/eb/7fcceb74002c5ef2eb162b8f91fd4d42561b0e177a009d34a9\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110743 sha256=b78dc9b42d30c83edaf64cc3e8d1ce2532b40627f7304b910f169afcaa0eb185\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/dc/2b/9cd600d483c04af3353d66623056fc03faed76b7518faae4df\n",
            "Successfully built backgroundremover moviepy\n",
            "Installing collected packages: urllib3, six, idna, requests, Pillow, scipy, proglog, imageio-ffmpeg, imageio, commandlines, waitress, pymatting, moviepy, more-itertools, hsh, filetype, ffmpeg-python, backgroundremover\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.13.0\n",
            "    Uninstalling more-itertools-8.13.0:\n",
            "      Successfully uninstalled more-itertools-8.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.1.1 backgroundremover-0.1.9 commandlines-0.4.1 ffmpeg-python-0.2.0 filetype-1.0.13 hsh-1.1.0 idna-3.3 imageio-2.9.0 imageio-ffmpeg-0.4.7 more-itertools-8.7.0 moviepy-1.0.3 proglog-0.1.10 pymatting-1.1.5 requests-2.27.1 scipy-1.7.3 six-1.16.0 urllib3-1.26.6 waitress-2.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Pillow 8.1.1\n",
            "Uninstalling Pillow-8.1.1:\n",
            "  Successfully uninstalled Pillow-8.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-9.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 9.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "backgroundremover 0.1.9 requires Pillow==8.1.1, but you have pillow 9.1.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install chumpy\n",
        "!pip install facenet_pytorch # for face detection\n",
        "#!pip install rembg[gpu] #cannot use for now -requires python 3.9 version\n",
        "!pip install backgroundremover #for background removal\n",
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1CG5ze_weMZ"
      },
      "source": [
        "### Install Pytorch3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5JxTOcWcp5gH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d84b263-b6b0-49e4-bc20-97405bae846c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  404k    0  404k    0     0  1082k      0 --:--:-- --:--:-- --:--:-- 1082k\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git@stable\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git (to revision stable) to /tmp/pip-req-build-o8vnt1qw\n",
            "  Running command git clone -q https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-o8vnt1qw\n",
            "  Running command git checkout -q 2bd65027ca5c3b87b77d4f05b8eacae58d8d106f\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.2) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 18.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.2) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.2) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.2) (9.1.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.2) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: pytorch3d, fvcore\n",
            "  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch3d: filename=pytorch3d-0.6.2-cp37-cp37m-linux_x86_64.whl size=31501470 sha256=85e5ca54d2739ee04e210002238474de3330ee5949b04e4dfce7801e2d577a7a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2oe7s1pl/wheels/4c/03/f0/326bb241eb86a155a12f217c81e163fbba48424bb84fa22074\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=7ac53f6a772882c1f0a339a77ac5fc812c3fd146ede1033a6f63aa0be7e0c0f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "Successfully built pytorch3d fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, fvcore, pytorch3d\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.5.post20220512 iopath-0.1.9 portalocker-2.4.0 pytorch3d-0.6.2 pyyaml-6.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.10.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rAlfgdV9Po8",
        "outputId": "c307336b-2ebd-4d1a-8dab-8ea628d678c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "import torch\n",
        "import numpy as np\n",
        "from pytorch3d.io import load_objs_as_meshes, load_obj\n",
        "from pytorch3d.structures import Meshes\n",
        "\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    OpenGLOrthographicCameras, \n",
        "    FoVPerspectiveCameras,\n",
        "    PerspectiveCameras,\n",
        "    PointLights, \n",
        "    DirectionalLights, \n",
        "    Materials, \n",
        "    RasterizationSettings, \n",
        "    MeshRenderer, \n",
        "    MeshRasterizer,  \n",
        "    HardPhongShader,\n",
        "    SoftPhongShader,\n",
        "    SoftSilhouetteShader,\n",
        "    BlendParams,\n",
        "    TexturesVertex,\n",
        "    TexturesUV\n",
        ")\n",
        "\n",
        "from pytorch3d.transforms import matrix_to_quaternion, quaternion_to_axis_angle, matrix_to_rotation_6d, axis_angle_to_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czaLoYwnwnp7"
      },
      "source": [
        "### Install FLAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2So2D4iwqDw",
        "outputId": "3ca603b5-ff2a-45b0-95b5-f6618dd658b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/voca/FLAME2020.zip\n",
            "  inflating: /content/FLAME//female_model.pkl  \n",
            "  inflating: /content/FLAME//generic_model.pkl  \n",
            "  inflating: /content/FLAME//male_model.pkl  \n",
            "  inflating: /content/FLAME//Readme.pdf  \n"
          ]
        }
      ],
      "source": [
        "flame_model = '/content/drive/MyDrive/voca/FLAME2020.zip'\n",
        "#!unzip [flame_model] -d /content/sample_data/\n",
        "flame_path = \"/content/FLAME/\"\n",
        "os.makedirs(flame_path, exist_ok=True)\n",
        "!unzip /content/drive/MyDrive/voca/FLAME2020.zip -d $flame_path/ "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get landmarks.npy which holds all the static and dynamic landmarks for FLAME\n",
        "!wget \"https://github.com/YadiraF/DECA/blob/master/data/landmark_embedding.npy?raw=true\" -O /content/FLAME/landmark_embedding.npy\n",
        "\n",
        "# Get texture info for texture regression\n",
        "!wget \"https://github.com/YadiraF/DECA/blob/master/data/texture_data_256.npy?raw=true\" -O /content/FLAME/texture_data_256.npy\n",
        "\n",
        "# Get template head model, to retrieve faces\n",
        "!wget \"https://raw.githubusercontent.com/YadiraF/DECA/master/data/head_template.obj\" -O /content/FLAME/head_template.obj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dH76Bp2j6Mp",
        "outputId": "5b1fcbd7-80f0-46a7-de52-d3a9e18240d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-02 13:04:24--  https://github.com/YadiraF/DECA/blob/master/data/landmark_embedding.npy?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/YadiraF/DECA/raw/master/data/landmark_embedding.npy [following]\n",
            "--2022-06-02 13:04:24--  https://github.com/YadiraF/DECA/raw/master/data/landmark_embedding.npy\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/YadiraF/DECA/master/data/landmark_embedding.npy [following]\n",
            "--2022-06-02 13:04:25--  https://raw.githubusercontent.com/YadiraF/DECA/master/data/landmark_embedding.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31292 (31K) [application/octet-stream]\n",
            "Saving to: ‘/content/FLAME/landmark_embedding.npy’\n",
            "\n",
            "/content/FLAME/land 100%[===================>]  30.56K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-06-02 13:04:25 (20.3 MB/s) - ‘/content/FLAME/landmark_embedding.npy’ saved [31292/31292]\n",
            "\n",
            "--2022-06-02 13:04:25--  https://github.com/YadiraF/DECA/blob/master/data/texture_data_256.npy?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/YadiraF/DECA/raw/master/data/texture_data_256.npy [following]\n",
            "--2022-06-02 13:04:25--  https://github.com/YadiraF/DECA/raw/master/data/texture_data_256.npy\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/YadiraF/DECA/master/data/texture_data_256.npy [following]\n",
            "--2022-06-02 13:04:25--  https://raw.githubusercontent.com/YadiraF/DECA/master/data/texture_data_256.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6677908 (6.4M) [application/octet-stream]\n",
            "Saving to: ‘/content/FLAME/texture_data_256.npy’\n",
            "\n",
            "/content/FLAME/text 100%[===================>]   6.37M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-06-02 13:04:26 (145 MB/s) - ‘/content/FLAME/texture_data_256.npy’ saved [6677908/6677908]\n",
            "\n",
            "--2022-06-02 13:04:26--  https://raw.githubusercontent.com/YadiraF/DECA/master/data/head_template.obj\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 563358 (550K) [text/plain]\n",
            "Saving to: ‘/content/FLAME/head_tempalte.obj’\n",
            "\n",
            "/content/FLAME/head 100%[===================>] 550.15K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-06-02 13:04:27 (23.6 MB/s) - ‘/content/FLAME/head_tempalte.obj’ saved [563358/563358]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/FLAME_albedo_from_BFM.npz /content/FLAME/FLAME_albedo_from_BFM.npz # get texture FLAME_albedo map from BFM model"
      ],
      "metadata": {
        "id": "mYJC5STWuW5d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgHy6nxFZCUz",
        "outputId": "02ad5644-049b-4372-9d85-2d03459505f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting github-clone\n",
            "  Downloading github_clone-1.2.0-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from github-clone) (2.27.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from github-clone) (0.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->github-clone) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->github-clone) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->github-clone) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->github-clone) (1.26.6)\n",
            "Installing collected packages: github-clone\n",
            "Successfully installed github-clone-1.2.0\n",
            "Cloning into 'smplx'...\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "#Sparse git clone of SMLPX library\n",
        "!pip install github-clone\n",
        "!ghclone \"https://github.com/vchoutas/smplx/tree/master/smplx\" # library from Vasilis Choutas with FLAME library "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-NAI4s0S7yP",
        "outputId": "0c51222b-6173-4086-d74e-32b144968d77",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/old.py\n"
          ]
        }
      ],
      "source": [
        "# @title old FLAME.py\n",
        "%%writefile /content/old.py\n",
        "\"\"\"\n",
        "FLAME Layer: Implementation of the 3D Statistical Face model in PyTorch\n",
        "\n",
        "It is designed in a way to directly plug in as a decoder layer in a \n",
        "Deep learning framework for training and testing\n",
        "\n",
        "It can also be used for 2D or 3D optimisation applications\n",
        "\n",
        "Author: Soubhik Sanyal\n",
        "Copyright (c) 2019, Soubhik Sanyal\n",
        "All rights reserved.\n",
        "\n",
        "Max-Planck-Gesellschaft zur Foerderung der Wissenschaften e.V. (MPG) is holder of all proprietary rights on this\n",
        "computer program.\n",
        "You can only use this computer program if you have closed a license agreement with MPG or you get the right to use\n",
        "the computer program from someone who is authorized to grant you that right.\n",
        "Any use of the computer program without a valid license is prohibited and liable to prosecution.\n",
        "Copyright 2019 Max-Planck-Gesellschaft zur Foerderung der Wissenschaften e.V. (MPG). acting on behalf of its\n",
        "Max Planck Institute for Intelligent Systems and the Max Planck Institute for Biological Cybernetics.\n",
        "All rights reserved.\n",
        "\n",
        "More information about FLAME is available at http://flame.is.tue.mpg.de.\n",
        "\n",
        "For questions regarding the PyTorch implementation please contact soubhik.sanyal@tuebingen.mpg.de\n",
        "\"\"\"\n",
        "# Modified from smplx code [https://github.com/vchoutas/smplx] for FLAME\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "from smplx.lbs import lbs, batch_rodrigues, vertices2landmarks, find_dynamic_lmk_idx_and_bcoords\n",
        "from smplx.utils import Struct, to_tensor, to_np, rot_mat_to_euler\n",
        "\n",
        "\n",
        "class FLAME(nn.Module):\n",
        "    \"\"\"\n",
        "    Given flame parameters this class generates a differentiable FLAME function\n",
        "    which outputs the a mesh and 3D facial landmarks\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(FLAME, self).__init__()\n",
        "        print(\"creating the FLAME Decoder\")\n",
        "        with open(config.flame_model_path, 'rb') as f:\n",
        "            self.flame_model = Struct(**pickle.load(f, encoding='latin1'))\n",
        "        self.NECK_IDX = 1\n",
        "        self.batch_size = config.batch_size\n",
        "        self.dtype = torch.float32\n",
        "        self.use_face_contour = config.use_face_contour\n",
        "        self.faces = self.flame_model.f\n",
        "        self.register_buffer('faces_tensor',\n",
        "                             to_tensor(to_np(self.faces, dtype=np.int64),\n",
        "                                       dtype=torch.long))\n",
        "\n",
        "        # Fixing remaining Shape betas\n",
        "        # There are total 300 shape parameters to control FLAME; But one can use the first few parameters to express\n",
        "        # the shape. For example 100 shape parameters are used for RingNet project \n",
        "        default_shape = torch.zeros([self.batch_size, 300-config.shape_params],\n",
        "                                            dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter('shape_betas', nn.Parameter(default_shape,\n",
        "                                                      requires_grad=False))\n",
        "\n",
        "        # Fixing remaining expression betas\n",
        "        # There are total 100 shape expression parameters to control FLAME; But one can use the first few parameters to express\n",
        "        # the expression. For example 50 expression parameters are used for RingNet project \n",
        "        default_exp = torch.zeros([self.batch_size, 100 - config.expression_params],\n",
        "                                    dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter('expression_betas', nn.Parameter(default_exp,\n",
        "                                                            requires_grad=False))\n",
        "\n",
        "        # Eyeball and neck rotation\n",
        "        default_eyball_pose = torch.zeros([self.batch_size, 6],\n",
        "                                    dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter('eye_pose', nn.Parameter(default_eyball_pose,\n",
        "                                                            requires_grad=False))\n",
        "\n",
        "        default_neck_pose = torch.zeros([self.batch_size, 3],\n",
        "                                    dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter('neck_pose', nn.Parameter(default_neck_pose,\n",
        "                                                            requires_grad=False))\n",
        "\n",
        "        # Fixing 3D translation since we use translation in the image plane\n",
        "\n",
        "        self.use_3D_translation = config.use_3D_translation\n",
        "\n",
        "        default_transl = torch.zeros([self.batch_size, 3],\n",
        "                                     dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter(\n",
        "            'transl',\n",
        "            nn.Parameter(default_transl, requires_grad=False))\n",
        "\n",
        "        # The vertices of the template model\n",
        "        self.register_buffer('v_template',\n",
        "                             to_tensor(to_np(self.flame_model.v_template),\n",
        "                                       dtype=self.dtype))\n",
        "\n",
        "        # The shape components\n",
        "        shapedirs = self.flame_model.shapedirs\n",
        "        # The shape components\n",
        "        self.register_buffer(\n",
        "            'shapedirs',\n",
        "            to_tensor(to_np(shapedirs), dtype=self.dtype))\n",
        "\n",
        "        j_regressor = to_tensor(to_np(\n",
        "            self.flame_model.J_regressor), dtype=self.dtype)\n",
        "        self.register_buffer('J_regressor', j_regressor)\n",
        "\n",
        "        # Pose blend shape basis\n",
        "        num_pose_basis = self.flame_model.posedirs.shape[-1]\n",
        "        posedirs = np.reshape(self.flame_model.posedirs, [-1, num_pose_basis]).T\n",
        "        self.register_buffer('posedirs',\n",
        "                             to_tensor(to_np(posedirs), dtype=self.dtype))\n",
        "\n",
        "        # indices of parents for each joints\n",
        "        parents = to_tensor(to_np(self.flame_model.kintree_table[0])).long()\n",
        "        parents[0] = -1\n",
        "        self.register_buffer('parents', parents)\n",
        "\n",
        "        self.register_buffer('lbs_weights',\n",
        "                             to_tensor(to_np(self.flame_model.weights), dtype=self.dtype))\n",
        "\n",
        "        # Static and Dynamic Landmark embeddings for FLAME\n",
        "\n",
        "        with open(config.static_landmark_embedding_path, 'rb') as f:\n",
        "            static_embeddings = Struct(**pickle.load(f, encoding='latin1'))\n",
        "\n",
        "        lmk_faces_idx = (static_embeddings.lmk_face_idx).astype(np.int64)\n",
        "        self.register_buffer('lmk_faces_idx',\n",
        "                             torch.tensor(lmk_faces_idx, dtype=torch.long))\n",
        "        lmk_bary_coords = static_embeddings.lmk_b_coords\n",
        "        self.register_buffer('lmk_bary_coords',\n",
        "                             torch.tensor(lmk_bary_coords, dtype=self.dtype))\n",
        "\n",
        "        if self.use_face_contour:\n",
        "            conture_embeddings = np.load(config.dynamic_landmark_embedding_path,\n",
        "                allow_pickle=True, encoding='latin1')\n",
        "            conture_embeddings = conture_embeddings[()]\n",
        "            dynamic_lmk_faces_idx = np.array(conture_embeddings['lmk_face_idx']).astype(np.int64)\n",
        "            dynamic_lmk_faces_idx = torch.tensor(\n",
        "                dynamic_lmk_faces_idx,\n",
        "                dtype=torch.long)\n",
        "            self.register_buffer('dynamic_lmk_faces_idx',\n",
        "                                 dynamic_lmk_faces_idx)\n",
        "\n",
        "            dynamic_lmk_bary_coords = conture_embeddings['lmk_b_coords']\n",
        "            dynamic_lmk_bary_coords = torch.tensor(\n",
        "                dynamic_lmk_bary_coords, dtype=self.dtype)\n",
        "            self.register_buffer('dynamic_lmk_bary_coords',\n",
        "                                 dynamic_lmk_bary_coords)\n",
        "\n",
        "            neck_kin_chain = []\n",
        "            curr_idx = torch.tensor(self.NECK_IDX, dtype=torch.long)\n",
        "            while curr_idx != -1:\n",
        "                neck_kin_chain.append(curr_idx)\n",
        "                curr_idx = self.parents[curr_idx]\n",
        "            self.register_buffer('neck_kin_chain',\n",
        "                                 torch.stack(neck_kin_chain))\n",
        "\n",
        "    def _find_dynamic_lmk_idx_and_bcoords(self, vertices, pose, dynamic_lmk_faces_idx,\n",
        "                                         dynamic_lmk_b_coords,\n",
        "                                         neck_kin_chain, dtype=torch.float32):\n",
        "        \"\"\"\n",
        "            Selects the face contour depending on the reletive position of the head\n",
        "            Input:\n",
        "                vertices: N X num_of_vertices X 3\n",
        "                pose: N X full pose\n",
        "                dynamic_lmk_faces_idx: The list of contour face indexes\n",
        "                dynamic_lmk_b_coords: The list of contour barycentric weights\n",
        "                neck_kin_chain: The tree to consider for the relative rotation\n",
        "                dtype: Data type\n",
        "            return:\n",
        "                The contour face indexes and the corresponding barycentric weights\n",
        "            Source: Modified for batches from https://github.com/vchoutas/smplx\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = vertices.shape[0]\n",
        "\n",
        "        aa_pose = torch.index_select(pose.view(batch_size, -1, 3), 1,\n",
        "                                     neck_kin_chain)\n",
        "        rot_mats = batch_rodrigues(\n",
        "            aa_pose.view(-1, 3), dtype=dtype).view(batch_size, -1, 3, 3)\n",
        "\n",
        "        rel_rot_mat = torch.eye(3, device=vertices.device,\n",
        "                                dtype=dtype).unsqueeze_(dim=0).expand(batch_size, -1, -1)\n",
        "        for idx in range(len(neck_kin_chain)):\n",
        "            rel_rot_mat = torch.bmm(rot_mats[:, idx], rel_rot_mat)\n",
        "\n",
        "        y_rot_angle = torch.round(\n",
        "            torch.clamp(-rot_mat_to_euler(rel_rot_mat) * 180.0 / np.pi,\n",
        "                        max=39)).to(dtype=torch.long)\n",
        "        neg_mask = y_rot_angle.lt(0).to(dtype=torch.long)\n",
        "        mask = y_rot_angle.lt(-39).to(dtype=torch.long)\n",
        "        neg_vals = mask * 78 + (1 - mask) * (39 - y_rot_angle)\n",
        "        y_rot_angle = (neg_mask * neg_vals +\n",
        "                       (1 - neg_mask) * y_rot_angle)\n",
        "\n",
        "        dyn_lmk_faces_idx = torch.index_select(dynamic_lmk_faces_idx,\n",
        "                                               0, y_rot_angle)\n",
        "        dyn_lmk_b_coords = torch.index_select(dynamic_lmk_b_coords,\n",
        "                                              0, y_rot_angle)\n",
        "\n",
        "        return dyn_lmk_faces_idx, dyn_lmk_b_coords\n",
        "\n",
        "    def forward(self, shape_params=None, expression_params=None, pose_params=None, neck_pose=None, eye_pose=None, transl=None):\n",
        "        \"\"\"\n",
        "            Input:\n",
        "                shape_params: N X number of shape parameters\n",
        "                expression_params: N X number of expression parameters\n",
        "                pose_params: N X number of pose parameters\n",
        "            return:\n",
        "                vertices: N X V X 3\n",
        "                landmarks: N X number of landmarks X 3\n",
        "        \"\"\"\n",
        "        betas = torch.cat([shape_params,self.shape_betas, expression_params, self.expression_betas], dim=1)\n",
        "        neck_pose = (neck_pose if neck_pose is not None else self.neck_pose)\n",
        "        eye_pose = (eye_pose if eye_pose is not None else self.eye_pose)\n",
        "        transl = (transl if transl is not None else self.transl)\n",
        "        full_pose = torch.cat([pose_params[:,:3], neck_pose, pose_params[:,3:], eye_pose], dim=1)\n",
        "        template_vertices = self.v_template.unsqueeze(0).repeat(self.batch_size, 1, 1)\n",
        "\n",
        "        vertices, _ = lbs(betas, full_pose, template_vertices,\n",
        "                               self.shapedirs, self.posedirs,\n",
        "                               self.J_regressor, self.parents,\n",
        "                               self.lbs_weights, dtype=self.dtype)\n",
        "\n",
        "        lmk_faces_idx = self.lmk_faces_idx.unsqueeze(dim=0).repeat(\n",
        "            self.batch_size, 1)\n",
        "        lmk_bary_coords = self.lmk_bary_coords.unsqueeze(dim=0).repeat(\n",
        "            self.batch_size, 1, 1)\n",
        "        if self.use_face_contour:\n",
        "\n",
        "            dyn_lmk_faces_idx, dyn_lmk_bary_coords = self._find_dynamic_lmk_idx_and_bcoords(\n",
        "                vertices, full_pose, self.dynamic_lmk_faces_idx,\n",
        "                self.dynamic_lmk_bary_coords,\n",
        "                self.neck_kin_chain, dtype=self.dtype)\n",
        "\n",
        "            lmk_faces_idx = torch.cat([dyn_lmk_faces_idx, lmk_faces_idx], 1)\n",
        "            lmk_bary_coords = torch.cat(\n",
        "                [dyn_lmk_bary_coords, lmk_bary_coords], 1)\n",
        "\n",
        "        landmarks = vertices2landmarks(vertices, self.faces_tensor,\n",
        "                                             lmk_faces_idx,\n",
        "                                             lmk_bary_coords)\n",
        "\n",
        "        if self.use_3D_translation:\n",
        "            landmarks += transl.unsqueeze(dim=1)\n",
        "            vertices += transl.unsqueeze(dim=1)\n",
        "\n",
        "        return vertices, landmarks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title New FLAME.py as Module.nn\n",
        "%%writefile /content/smplx/FLAME.py\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Max-Planck-Gesellschaft zur Förderung der Wissenschaften e.V. (MPG) is\n",
        "# holder of all proprietary rights on this computer program.\n",
        "# Using this computer program means that you agree to the terms \n",
        "# in the LICENSE file included with this software distribution. \n",
        "# Any use not explicitly granted by the LICENSE is prohibited.\n",
        "#\n",
        "# Copyright©2019 Max-Planck-Gesellschaft zur Förderung\n",
        "# der Wissenschaften e.V. (MPG). acting on behalf of its Max Planck Institute\n",
        "# for Intelligent Systems. All rights reserved.\n",
        "#\n",
        "# For comments or questions, please email us at deca@tue.mpg.de\n",
        "# For commercial licensing contact, please contact ps-license@tuebingen.mpg.de\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "sys.path.append(\"/content/smplx/\")\n",
        "from .lbs import lbs, batch_rodrigues, vertices2landmarks, rot_mat_to_euler\n",
        "\n",
        "def to_tensor(array, dtype=torch.float32):\n",
        "    if 'torch.tensor' not in str(type(array)):\n",
        "        return torch.tensor(array, dtype=dtype)\n",
        "def to_np(array, dtype=np.float32):\n",
        "    if 'scipy.sparse' in str(type(array)):\n",
        "        array = array.todense()\n",
        "    return np.array(array, dtype=dtype)\n",
        "\n",
        "class Struct(object):\n",
        "    def __init__(self, **kwargs):\n",
        "        for key, val in kwargs.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "class FLAME(nn.Module):\n",
        "    \"\"\"\n",
        "    borrowed from https://github.com/soubhiksanyal/FLAME_PyTorch/blob/master/FLAME.py\n",
        "    Given flame parameters this class generates a differentiable FLAME function\n",
        "    which outputs the a mesh and 2D/3D facial landmarks\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(FLAME, self).__init__()\n",
        "        print(\"creating the FLAME Decoder\")\n",
        "        with open(config.flame_model_path, 'rb') as f:\n",
        "            ss = pickle.load(f, encoding='latin1')\n",
        "            flame_model = Struct(**ss)\n",
        "\n",
        "        self.dtype = torch.float32\n",
        "        self.register_buffer('faces_tensor', to_tensor(to_np(flame_model.f, dtype=np.int64), dtype=torch.long))\n",
        "        # The vertices of the template model\n",
        "        self.register_buffer('v_template', to_tensor(to_np(flame_model.v_template), dtype=self.dtype))\n",
        "        # The shape components and expression\n",
        "        shapedirs = to_tensor(to_np(flame_model.shapedirs), dtype=self.dtype)\n",
        "        shapedirs = torch.cat([shapedirs[:,:,:config.n_shape], shapedirs[:,:,300:300+config.n_exp]], 2)\n",
        "        self.register_buffer('shapedirs', shapedirs)\n",
        "        # The pose components\n",
        "        num_pose_basis = flame_model.posedirs.shape[-1]\n",
        "        posedirs = np.reshape(flame_model.posedirs, [-1, num_pose_basis]).T\n",
        "        self.register_buffer('posedirs', to_tensor(to_np(posedirs), dtype=self.dtype))\n",
        "        # \n",
        "        self.register_buffer('J_regressor', to_tensor(to_np(flame_model.J_regressor), dtype=self.dtype))\n",
        "        parents = to_tensor(to_np(flame_model.kintree_table[0])).long(); parents[0] = -1\n",
        "        self.register_buffer('parents', parents)\n",
        "        self.register_buffer('lbs_weights', to_tensor(to_np(flame_model.weights), dtype=self.dtype))\n",
        "\n",
        "        # Fixing Eyeball and neck rotation\n",
        "        default_eyball_pose = torch.zeros([1, 6], dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter('eye_pose', nn.Parameter(default_eyball_pose,\n",
        "                                                         requires_grad=False))\n",
        "        default_neck_pose = torch.zeros([1, 3], dtype=self.dtype, requires_grad=False)\n",
        "        self.register_parameter('neck_pose', nn.Parameter(default_neck_pose,\n",
        "                                                          requires_grad=False))\n",
        "\n",
        "        # Static and Dynamic Landmark embeddings for FLAME\n",
        "        lmk_embeddings = np.load(config.flame_lmk_embedding_path, allow_pickle=True, encoding='latin1')\n",
        "        lmk_embeddings = lmk_embeddings[()]\n",
        "        self.register_buffer('lmk_faces_idx', torch.from_numpy(lmk_embeddings['static_lmk_faces_idx']).long())\n",
        "        self.register_buffer('lmk_bary_coords', torch.from_numpy(lmk_embeddings['static_lmk_bary_coords']).to(self.dtype))\n",
        "        self.register_buffer('dynamic_lmk_faces_idx', lmk_embeddings['dynamic_lmk_faces_idx'].long())\n",
        "        self.register_buffer('dynamic_lmk_bary_coords', lmk_embeddings['dynamic_lmk_bary_coords'].to(self.dtype))\n",
        "        self.register_buffer('full_lmk_faces_idx', torch.from_numpy(lmk_embeddings['full_lmk_faces_idx']).long())\n",
        "        self.register_buffer('full_lmk_bary_coords', torch.from_numpy(lmk_embeddings['full_lmk_bary_coords']).to(self.dtype))\n",
        "\n",
        "        neck_kin_chain = []; NECK_IDX=1\n",
        "        curr_idx = torch.tensor(NECK_IDX, dtype=torch.long)\n",
        "        while curr_idx != -1:\n",
        "            neck_kin_chain.append(curr_idx)\n",
        "            curr_idx = self.parents[curr_idx]\n",
        "        self.register_buffer('neck_kin_chain', torch.stack(neck_kin_chain))\n",
        "        \n",
        "    def _find_dynamic_lmk_idx_and_bcoords(self, pose, dynamic_lmk_faces_idx,\n",
        "                                          dynamic_lmk_b_coords,\n",
        "                                          neck_kin_chain, dtype=torch.float32):\n",
        "        \"\"\"\n",
        "            Selects the face contour depending on the reletive position of the head\n",
        "            Input:\n",
        "                vertices: N X num_of_vertices X 3\n",
        "                pose: N X full pose\n",
        "                dynamic_lmk_faces_idx: The list of contour face indexes\n",
        "                dynamic_lmk_b_coords: The list of contour barycentric weights\n",
        "                neck_kin_chain: The tree to consider for the relative rotation\n",
        "                dtype: Data type\n",
        "            return:\n",
        "                The contour face indexes and the corresponding barycentric weights\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = pose.shape[0]\n",
        "\n",
        "        aa_pose = torch.index_select(pose.view(batch_size, -1, 3), 1,\n",
        "                                     neck_kin_chain)\n",
        "        rot_mats = batch_rodrigues(\n",
        "            aa_pose.view(-1, 3), dtype=dtype).view(batch_size, -1, 3, 3)\n",
        "\n",
        "        rel_rot_mat = torch.eye(3, device=pose.device,\n",
        "                                dtype=dtype).unsqueeze_(dim=0).expand(batch_size, -1, -1)\n",
        "        for idx in range(len(neck_kin_chain)):\n",
        "            rel_rot_mat = torch.bmm(rot_mats[:, idx], rel_rot_mat)\n",
        "\n",
        "        y_rot_angle = torch.round(\n",
        "            torch.clamp(rot_mat_to_euler(rel_rot_mat) * 180.0 / np.pi,\n",
        "                        max=39)).to(dtype=torch.long)\n",
        "\n",
        "        neg_mask = y_rot_angle.lt(0).to(dtype=torch.long)\n",
        "        mask = y_rot_angle.lt(-39).to(dtype=torch.long)\n",
        "        neg_vals = mask * 78 + (1 - mask) * (39 - y_rot_angle)\n",
        "        y_rot_angle = (neg_mask * neg_vals +\n",
        "                       (1 - neg_mask) * y_rot_angle)\n",
        "\n",
        "        dyn_lmk_faces_idx = torch.index_select(dynamic_lmk_faces_idx,\n",
        "                                               0, y_rot_angle)\n",
        "        dyn_lmk_b_coords = torch.index_select(dynamic_lmk_b_coords,\n",
        "                                              0, y_rot_angle)\n",
        "        return dyn_lmk_faces_idx, dyn_lmk_b_coords\n",
        "\n",
        "    def _vertices2landmarks(self, vertices, faces, lmk_faces_idx, lmk_bary_coords):\n",
        "        \"\"\"\n",
        "            Calculates landmarks by barycentric interpolation\n",
        "            Input:\n",
        "                vertices: torch.tensor NxVx3, dtype = torch.float32\n",
        "                    The tensor of input vertices\n",
        "                faces: torch.tensor (N*F)x3, dtype = torch.long\n",
        "                    The faces of the mesh\n",
        "                lmk_faces_idx: torch.tensor N X L, dtype = torch.long\n",
        "                    The tensor with the indices of the faces used to calculate the\n",
        "                    landmarks.\n",
        "                lmk_bary_coords: torch.tensor N X L X 3, dtype = torch.float32\n",
        "                    The tensor of barycentric coordinates that are used to interpolate\n",
        "                    the landmarks\n",
        "\n",
        "            Returns:\n",
        "                landmarks: torch.tensor NxLx3, dtype = torch.float32\n",
        "                    The coordinates of the landmarks for each mesh in the batch\n",
        "        \"\"\"\n",
        "        # Extract the indices of the vertices for each face\n",
        "        # NxLx3\n",
        "        batch_size, num_verts = vertices.shape[:dd2]\n",
        "        lmk_faces = torch.index_select(faces, 0, lmk_faces_idx.view(-1)).view(\n",
        "            1, -1, 3).view(batch_size, lmk_faces_idx.shape[1], -1)\n",
        "\n",
        "        lmk_faces += torch.arange(batch_size, dtype=torch.long).view(-1, 1, 1).to(\n",
        "            device=vertices.device) * num_verts\n",
        "\n",
        "        lmk_vertices = vertices.view(-1, 3)[lmk_faces]\n",
        "        landmarks = torch.einsum('blfi,blf->bli', [lmk_vertices, lmk_bary_coords])\n",
        "        return landmarks\n",
        "\n",
        "    def seletec_3d68(self, vertices):\n",
        "        landmarks3d = vertices2landmarks(vertices, self.faces_tensor,\n",
        "                                       self.full_lmk_faces_idx.repeat(vertices.shape[0], 1),\n",
        "                                       self.full_lmk_bary_coords.repeat(vertices.shape[0], 1, 1))\n",
        "        return landmarks3d\n",
        "\n",
        "    def forward(self, shape_params=None, expression_params=None, pose_params=None, eye_pose_params=None):\n",
        "        \"\"\"\n",
        "            Input:\n",
        "                shape_params: N X number of shape parameters\n",
        "                expression_params: N X number of expression parameters\n",
        "                pose_params: N X number of pose parameters (6)\n",
        "            return:d\n",
        "                vertices: N X V X 3\n",
        "                landmarks: N X number of landmarks X 3\n",
        "        \"\"\"\n",
        "        batch_size = shape_params.shape[0]\n",
        "        if pose_params is None:\n",
        "            pose_params = self.eye_pose.expand(batch_size, -1)\n",
        "        if eye_pose_params is None:\n",
        "            eye_pose_params = self.eye_pose.expand(batch_size, -1)\n",
        "        betas = torch.cat([shape_params, expression_params], dim=1)\n",
        "        full_pose = torch.cat([pose_params[:, :3], self.neck_pose.expand(batch_size, -1), pose_params[:, 3:], eye_pose_params], dim=1)\n",
        "        template_vertices = self.v_template.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "\n",
        "        vertices, _ = lbs(betas, full_pose, template_vertices,\n",
        "                          self.shapedirs, self.posedirs,\n",
        "                          self.J_regressor, self.parents,\n",
        "                          self.lbs_weights, dtype=self.dtype)\n",
        "\n",
        "        lmk_faces_idx = self.lmk_faces_idx.unsqueeze(dim=0).expand(batch_size, -1)\n",
        "        lmk_bary_coords = self.lmk_bary_coords.unsqueeze(dim=0).expand(batch_size, -1, -1)\n",
        "        \n",
        "        dyn_lmk_faces_idx, dyn_lmk_bary_coords = self._find_dynamic_lmk_idx_and_bcoords(\n",
        "            full_pose, self.dynamic_lmk_faces_idx,\n",
        "            self.dynamic_lmk_bary_coords,\n",
        "            self.neck_kin_chain, dtype=self.dtype)\n",
        "        lmk_faces_idx = torch.cat([dyn_lmk_faces_idx, lmk_faces_idx], 1)\n",
        "        lmk_bary_coords = torch.cat([dyn_lmk_bary_coords, lmk_bary_coords], 1)\n",
        "\n",
        "        landmarks2d = vertices2landmarks(vertices, self.faces_tensor,\n",
        "                                       lmk_faces_idx,\n",
        "                                       lmk_bary_coords)\n",
        "        bz = vertices.shape[0]\n",
        "        landmarks3d = vertices2landmarks(vertices, self.faces_tensor,\n",
        "                                       self.full_lmk_faces_idx.repeat(bz, 1),\n",
        "                                       self.full_lmk_bary_coords.repeat(bz, 1, 1))\n",
        "        return vertices, landmarks2d, landmarks3d\n",
        "\n",
        "class FLAMETex(nn.Module):\n",
        "    \"\"\"\n",
        "    FLAME texture:\n",
        "    https://github.com/TimoBolkart/TF_FLAME/blob/ade0ab152300ec5f0e8555d6765411555c5ed43d/sample_texture.py#L64\n",
        "    FLAME texture converted from BFM:\n",
        "    https://github.com/TimoBolkart/BFM_to_FLAME\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(FLAMETex, self).__init__()\n",
        "        if config.tex_type == 'BFM':\n",
        "            mu_key = 'MU'\n",
        "            pc_key = 'PC'\n",
        "            n_pc = 199\n",
        "            tex_path = config.tex_path\n",
        "            tex_space = np.load(tex_path)\n",
        "            texture_mean = tex_space[mu_key].reshape(1, -1)\n",
        "            texture_basis = tex_space[pc_key].reshape(-1, n_pc)\n",
        "\n",
        "        elif config.tex_type == 'FLAME':\n",
        "            mu_key = 'mean'\n",
        "            pc_key = 'tex_dir'\n",
        "            n_pc = 200\n",
        "            tex_path = config.flame_tex_path\n",
        "            tex_space = np.load(tex_path)\n",
        "            texture_mean = tex_space[mu_key].reshape(1, -1)/255.\n",
        "            texture_basis = tex_space[pc_key].reshape(-1, n_pc)/255.\n",
        "        else:\n",
        "            print('texture type ', config.tex_type, 'not exist!')\n",
        "            raise NotImplementedError\n",
        "\n",
        "        n_tex = config.n_tex\n",
        "        num_components = texture_basis.shape[1]\n",
        "        texture_mean = torch.from_numpy(texture_mean).float()[None,...]\n",
        "        texture_basis = torch.from_numpy(texture_basis[:,:n_tex]).float()[None,...]\n",
        "        self.register_buffer('texture_mean', texture_mean)\n",
        "        self.register_buffer('texture_basis', texture_basis)\n",
        "\n",
        "    def forward(self, texcode):\n",
        "        '''\n",
        "        texcode: [batchsize, n_tex]\n",
        "        texture: [bz, 3, 256, 256], range: 0-1\n",
        "        '''\n",
        "        texture = self.texture_mean + (self.texture_basis*texcode[:,None,:]).sum(-1)\n",
        "        texture = texture.reshape(texcode.shape[0], 512, 512, 3).permute(0,3,1,2)\n",
        "        texture = F.interpolate(texture, [256, 256])\n",
        "        texture = texture[:,[2,1,0], :,:]\n",
        "        return texture "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "O2Pz675qbRmv",
        "outputId": "fd35cb2a-2eca-4fd5-c2a7-0341bd8700f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/smplx/FLAME.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9G9D7KezshV"
      },
      "source": [
        "## Image (GT) and Render(Prediction) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XWp-s70S0ekO"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import MTCNN as mtcnn\n",
        "\n",
        "def pad(img, new_size, old_size, color=[255, 255, 255]):\n",
        "  padded_img = np.full((new_size,new_size, 3), fill_value=tuple(color))\n",
        "\n",
        "  # compute center offset - same for square images\n",
        "  x_center = int((new_size - old_size) // 2)\n",
        "  y_center = int((new_size - old_size) // 2)\n",
        "\n",
        "  # copy img image into center of result image\n",
        "  padded_img[y_center:y_center+ old_size, \n",
        "        x_center:x_center+old_size] = img\n",
        "  return padded_img\n",
        "\n",
        "def remove_background(img=\"\", img_path=\"\", color=\"\"):\n",
        "  ''' Remove background from image array or imgage path\n",
        "      img: image 0-255, uint8, rgb, [h, w, 3]\n",
        "      img_path: path to image\n",
        "      return: detected box\n",
        "  '''\n",
        "  try:\n",
        "    #img = np.uint8(img)\n",
        "    cropped_img = Image.fromarray(img)\n",
        "  except:\n",
        "    print(\"Img array was not loaded\")\n",
        "    cropped_img = Image.open(img_path)\n",
        "    \n",
        "  temp_path = \"/content/sample_data/temp.jpg\"\n",
        "  temp2_path = \"/content/sample_data/temp2.jpg\"\n",
        "  cropped_img.save(temp_path)\n",
        "  !backgroundremover -i $temp_path -o $temp2_path\n",
        "  img = np.asarray(Image.open(temp2_path).convert('RGB'))\n",
        "  return img\n",
        "  \n",
        "\n",
        "def crop_img(img_path=\"\", img=\"\"):\n",
        "  ''' Detect face and crop image\n",
        "      img_path: path to image\n",
        "      return: detected box\n",
        "  '''\n",
        "  try:\n",
        "    temp_img = img.copy()\n",
        "    img = img.copy()\n",
        "  except:\n",
        "    temp_img = np.asarray(Image.open(img_path).convert('RGB'))\n",
        "    img = np.asarray(Image.open(img_path).convert('RGB'))\n",
        "  face_detector = mtcnn(keep_all=True)\n",
        "  out = face_detector.detect(temp_img)\n",
        "  print(out)\n",
        "  if out[0] is None:\n",
        "    print(\"No face is detected\")\n",
        "    return img\n",
        "  else:\n",
        "    bbox = out[0][0].squeeze().astype(int)\n",
        "    y1 = bbox[0]\n",
        "    y2 = bbox[2]\n",
        "    x1 = bbox[1]\n",
        "    x2 = bbox[3]\n",
        "    dx = int((x2-x1)/4) # use this to catch the shoulders\n",
        "    dy = int((y2-y1)/4) # and neck and hair\n",
        "    cropped_img = img.copy()[abs(x1-dx):abs(x2+dx), abs(y1-dy):abs(y2+dy)]\n",
        "    return cropped_img\n",
        "\n",
        "def img_to_tensor(img_path):\n",
        "  ''' img should be a float value [0,1] '''\n",
        "  img = np.asarray(Image.open(img_path).convert('RGB'))\n",
        "  img = img / 255 #normalized like the render\n",
        "  tensor = torch.Tensor(img).unsqueeze(0)\n",
        "  return tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(img_path, cropped=True, img_size=256,\n",
        "             background_remove=False, scale=1, pad_color=[255,255,255],\n",
        "             render_size=200, replace=False):\n",
        "    ''' Load an image as a torch sensor. This is used to preprocess gt images \n",
        "        for mesh fitting\n",
        "        img_path: path to image (str)\n",
        "        cropped: crop image/face detection (boolean)\n",
        "        img_size: maximum h and w of image (int)\n",
        "        background_remove: remove background/replace with transparent background(boolean)\n",
        "        scale: zoom in/zoom out effect of face in image frame (float: [0-1])\n",
        "        pad_color: RGB channel for image padding (int array: (3,1))\n",
        "        render_size: this should match the render size and corresponds to the size of the face in the image frame (int)\n",
        "    '''\n",
        "\n",
        "\n",
        "    if cropped:\n",
        "      img = crop_img(img_path)\n",
        "    else:\n",
        "      img = np.asarray(Image.open(img_path).convert('RGB'))\n",
        "    h, w, _ = img.shape\n",
        "    max_dim = max(h, w)\n",
        "\n",
        "    if background_remove:\n",
        "      img = remove_background(img)\n",
        "      img [(img == 1)] = 255\n",
        "      img [(img == 0)] = 255\n",
        "\n",
        "    try:\n",
        "      scaled_size = int((scale) * img_size) # face imgs of only squares\n",
        "      img = cv2.resize(img, (scaled_size, scaled_size), interpolation=cv2.INTER_AREA)\n",
        "    except:\n",
        "      print(\"Scale value needs to be a float value between (0-1]\")\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    img = pad(img, new_size=img_size, old_size=scaled_size, color=pad_color)\n",
        "\n",
        "    \n",
        "    img = img / 255 #normalized like the render\n",
        "    if replace:\n",
        "      img_path = str(img_path.split(\".\")[:-1][0]) + \".png\"\n",
        "      plt.imsave(img_path, img)\n",
        "    tensor = torch.Tensor(img).unsqueeze(0)\n",
        "    #tensor = tensor.to(torch.float32)\n",
        "          \n",
        "    return tensor"
      ],
      "metadata": {
        "id": "4j8kJs3A8NMR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7HDkbaDK-5DL",
        "outputId": "f1854f08-a7fb-418e-a3ef-cc335db338f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-02 13:17:23--  https://www.dropbox.com/sh/56osnf7uohbxg9u/AAAHJUgA_IhOTqB64W7BtuSya?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/dl/56osnf7uohbxg9u/AAAHJUgA_IhOTqB64W7BtuSya [following]\n",
            "--2022-06-02 13:17:23--  https://www.dropbox.com/sh/dl/56osnf7uohbxg9u/AAAHJUgA_IhOTqB64W7BtuSya\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3a893cd42b82063fcd4872e433.dl.dropboxusercontent.com/zip_download_get/BJ0XgMmUuPSnXnICLlS9xpH8CeL6-xoiXVHO2vR8KT-sVGqcgkpivtBUJDidRABGRuIcOsEbw0rqD-gJAs4EO5YlWJ_4rbzc1H6iBQyqFJP7Jw?dl=1# [following]\n",
            "--2022-06-02 13:17:24--  https://uc3a893cd42b82063fcd4872e433.dl.dropboxusercontent.com/zip_download_get/BJ0XgMmUuPSnXnICLlS9xpH8CeL6-xoiXVHO2vR8KT-sVGqcgkpivtBUJDidRABGRuIcOsEbw0rqD-gJAs4EO5YlWJ_4rbzc1H6iBQyqFJP7Jw?dl=1\n",
            "Resolving uc3a893cd42b82063fcd4872e433.dl.dropboxusercontent.com (uc3a893cd42b82063fcd4872e433.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc3a893cd42b82063fcd4872e433.dl.dropboxusercontent.com (uc3a893cd42b82063fcd4872e433.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 394372203 (376M) [application/zip]\n",
            "Saving to: ‘/content/dataset’\n",
            "\n",
            "/content/dataset    100%[===================>] 376.10M  63.2MB/s    in 9.3s    \n",
            "\n",
            "2022-06-02 13:17:34 (40.5 MB/s) - ‘/content/dataset’ saved [394372203/394372203]\n",
            "\n",
            "Archive:  /content/dataset\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            "   creating: /content/sample_dataset/lewis/\n",
            "   creating: /content/sample_dataset/DECA_results/\n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0001.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0004.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0018.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0025.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0036.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0041.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0045.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0005.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0006.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0014.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0010.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0011.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0017.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0024.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0038.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0044.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0048.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0008.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0012.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0034.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0037.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0022.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0023.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0027.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0030.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0042.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0016.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0019.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0029.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0007.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0026.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0033.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0035.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0009.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0015.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0040.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0043.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0049.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0031.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0032.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0020.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0046.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0047.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0000.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0021.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0028.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0002.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0003.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0013.jpg  \n",
            " extracting: /content/sample_dataset/lewis/lewis_frame0039.jpg  \n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0036/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0000/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0028/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0038/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0041/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0030/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0022/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0037/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0016/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0043/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0020/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0007/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0004/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0006/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0032/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0033/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0031/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0034/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0042/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0039/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0008/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0044/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0046/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0002/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0048/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0018/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0001/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0005/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0019/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0035/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0045/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0012/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0015/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0029/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0040/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0025/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0017/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0047/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0049/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0003/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0024/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0026/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0013/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0009/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0010/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0014/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0021/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0027/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0011/\n",
            "   creating: /content/sample_dataset/DECA_results/lewis_frame0023/\n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/flame_params.pkl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/lewis_frame0036.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/lewis_frame0036.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/lewis_frame0036.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/lewis_frame0028.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/lewis_frame0028.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/lewis_frame0028.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/lewis_frame0038.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/lewis_frame0038.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/lewis_frame0038.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/lewis_frame0041.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/lewis_frame0041.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/lewis_frame0041.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/lewis_frame0030.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/lewis_frame0030.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/lewis_frame0030.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/lewis_frame0022.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/lewis_frame0022.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/lewis_frame0022.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/lewis_frame0037.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/lewis_frame0037.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/lewis_frame0037.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/lewis_frame0016.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/lewis_frame0016.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/lewis_frame0016.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/lewis_frame0043.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/lewis_frame0043.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/lewis_frame0043.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/lewis_frame0020.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/lewis_frame0020.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/lewis_frame0020.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/lewis_frame0007.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/lewis_frame0007.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/lewis_frame0007.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/lewis_frame0004.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/lewis_frame0004.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/lewis_frame0004.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/lewis_frame0006.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/lewis_frame0006.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/lewis_frame0006.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/lewis_frame0032.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/lewis_frame0032.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/lewis_frame0032.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/lewis_frame0033.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/lewis_frame0033.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/lewis_frame0033.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/lewis_frame0031.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/lewis_frame0031.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/lewis_frame0031.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/lewis_frame0034.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/lewis_frame0034.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/lewis_frame0034.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/lewis_frame0042.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/lewis_frame0042.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/lewis_frame0042.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/lewis_frame0039.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/lewis_frame0039.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/lewis_frame0039.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/lewis_frame0008.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/lewis_frame0008.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/lewis_frame0008.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/lewis_frame0044.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/lewis_frame0044.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/lewis_frame0044.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/lewis_frame0046.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/lewis_frame0046.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/lewis_frame0046.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/lewis_frame0002.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/lewis_frame0002.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/lewis_frame0002.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/lewis_frame0048.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/lewis_frame0048.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/lewis_frame0048.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/lewis_frame0018.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/lewis_frame0018.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/lewis_frame0018.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/lewis_frame0001.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/lewis_frame0001.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/lewis_frame0001.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/lewis_frame0005.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/lewis_frame0005.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/lewis_frame0005.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/lewis_frame0019.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/lewis_frame0019.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/lewis_frame0019.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/lewis_frame0035.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/lewis_frame0035.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/lewis_frame0035.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/lewis_frame0045.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/lewis_frame0045.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/lewis_frame0045.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/lewis_frame0012.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/lewis_frame0012.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/lewis_frame0012.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/lewis_frame0015.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/lewis_frame0015.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/lewis_frame0015.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/lewis_frame0029.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/lewis_frame0029.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/lewis_frame0029.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/lewis_frame0040.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/lewis_frame0040.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/lewis_frame0040.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/lewis_frame0025.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/lewis_frame0025.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/lewis_frame0025.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/lewis_frame0017.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/lewis_frame0017.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/lewis_frame0017.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/lewis_frame0047.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/lewis_frame0047.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/lewis_frame0047.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/lewis_frame0049.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/lewis_frame0049.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/lewis_frame0049.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/lewis_frame0003.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/lewis_frame0003.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/lewis_frame0003.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/lewis_frame0024.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/lewis_frame0024.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/lewis_frame0024.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/lewis_frame0026.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/lewis_frame0026.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/lewis_frame0026.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/lewis_frame0013.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/lewis_frame0013.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/lewis_frame0013.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/lewis_frame0009.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/lewis_frame0009.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/lewis_frame0009.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/lewis_frame0010.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/lewis_frame0010.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/lewis_frame0010.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/lewis_frame0014.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/lewis_frame0014.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/lewis_frame0014.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/lewis_frame0021.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/lewis_frame0021.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/lewis_frame0021.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/lewis_frame0027.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/lewis_frame0027.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/lewis_frame0027.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/lewis_frame0011.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/lewis_frame0011.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/lewis_frame0011.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/lewis_frame0023.mtl  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/lewis_frame0023.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/lewis_frame0023.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/lewis_frame0036_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/lewis_frame0028_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/lewis_frame0038_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/lewis_frame0041_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/lewis_frame0030_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/lewis_frame0022_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/lewis_frame0037_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/lewis_frame0016_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/lewis_frame0043_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/lewis_frame0020_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/lewis_frame0007_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/lewis_frame0004_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/lewis_frame0006_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/lewis_frame0032_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/lewis_frame0033_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/lewis_frame0031_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/lewis_frame0034_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/lewis_frame0042_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/lewis_frame0039_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/lewis_frame0008_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/lewis_frame0044_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/lewis_frame0046_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/lewis_frame0002_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/lewis_frame0048_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/lewis_frame0018_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/lewis_frame0001_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/lewis_frame0005_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/lewis_frame0019_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/lewis_frame0035_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/lewis_frame0045_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/lewis_frame0012_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/lewis_frame0015_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/lewis_frame0029_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/lewis_frame0040_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/lewis_frame0025_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/lewis_frame0017_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/lewis_frame0047_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/lewis_frame0049_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/lewis_frame0003_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/lewis_frame0024_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/lewis_frame0026_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/lewis_frame0013_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/lewis_frame0009_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/lewis_frame0010_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/lewis_frame0014_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/lewis_frame0021_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/lewis_frame0027_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/lewis_frame0011_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/lewis_frame0023_depth.jpg  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/lewis_frame0036_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/lewis_frame0028_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/lewis_frame0038_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/lewis_frame0041_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/lewis_frame0030_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/lewis_frame0022_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/lewis_frame0037_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/lewis_frame0016_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/lewis_frame0043_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/lewis_frame0020_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/lewis_frame0007_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/lewis_frame0004_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/lewis_frame0006_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/lewis_frame0032_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/lewis_frame0033_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/lewis_frame0031_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/lewis_frame0034_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/lewis_frame0042_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/lewis_frame0039_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/lewis_frame0008_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/lewis_frame0044_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/lewis_frame0046_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/lewis_frame0002_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/lewis_frame0048_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/lewis_frame0018_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/lewis_frame0001_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/lewis_frame0005_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/lewis_frame0019_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/lewis_frame0035_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/lewis_frame0045_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/lewis_frame0012_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/lewis_frame0015_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/lewis_frame0029_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/lewis_frame0040_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/lewis_frame0025_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/lewis_frame0017_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/lewis_frame0047_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/lewis_frame0049_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/lewis_frame0003_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/lewis_frame0024_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/lewis_frame0026_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/lewis_frame0013_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/lewis_frame0009_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/lewis_frame0010_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/lewis_frame0014_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/lewis_frame0021_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/lewis_frame0027_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/lewis_frame0011_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/lewis_frame0023_detail.obj  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0036/lewis_frame0036_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0028/lewis_frame0028_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0038/lewis_frame0038_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0041/lewis_frame0041_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0030/lewis_frame0030_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0022/lewis_frame0022_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0037/lewis_frame0037_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0016/lewis_frame0016_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0043/lewis_frame0043_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0020/lewis_frame0020_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0007/lewis_frame0007_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0004/lewis_frame0004_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0006/lewis_frame0006_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0032/lewis_frame0032_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0033/lewis_frame0033_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0031/lewis_frame0031_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0034/lewis_frame0034_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0042/lewis_frame0042_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0039/lewis_frame0039_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0008/lewis_frame0008_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0044/lewis_frame0044_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0046/lewis_frame0046_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0002/lewis_frame0002_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0048/lewis_frame0048_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0018/lewis_frame0018_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0001/lewis_frame0001_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0005/lewis_frame0005_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0019/lewis_frame0019_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0035/lewis_frame0035_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0045/lewis_frame0045_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0012/lewis_frame0012_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0015/lewis_frame0015_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0029/lewis_frame0029_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0040/lewis_frame0040_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0025/lewis_frame0025_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0017/lewis_frame0017_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0047/lewis_frame0047_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0049/lewis_frame0049_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0003/lewis_frame0003_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0024/lewis_frame0024_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0026/lewis_frame0026_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0013/lewis_frame0013_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0009/lewis_frame0009_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0010/lewis_frame0010_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0014/lewis_frame0014_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0021/lewis_frame0021_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0027/lewis_frame0027_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0011/lewis_frame0011_normals.png  \n",
            " extracting: /content/sample_dataset/DECA_results/lewis_frame0023/lewis_frame0023_normals.png  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# or just access via google drive\\n!cp -r /content/drive/MyDrive/deca/sample_dataset /content/sample_dataset\\nsample_dataset_path = \"/content/drive/MyDrive/deca/sample_dataset\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Download data\n",
        "\n",
        "male_dataset = \"https://www.dropbox.com/sh/56osnf7uohbxg9u/AAAHJUgA_IhOTqB64W7BtuSya?dl=1\"\n",
        "female_dataset = \"\"\n",
        "sample_dataset_path = \"/content/sample_dataset/\"\n",
        "!wget {male_dataset} -O /content/dataset # male dataset (lewis_hamilton)\n",
        "!unzip /content/dataset -d {sample_dataset_path}\n",
        "\n",
        "'''\n",
        "# or just access via google drive\n",
        "!cp -r /content/drive/MyDrive/deca/sample_dataset /content/sample_dataset\n",
        "sample_dataset_path = \"/content/drive/MyDrive/deca/sample_dataset\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example image\n",
        "path = \"/content/sample_dataset/lewis/lewis_frame0015.jpg\"\n",
        "img = load_img(path, background_remove=True, replace=False, scale=0.3)\n",
        "img = img.squeeze(0).detach().cpu().numpy()\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "JXfHed12oD45",
        "outputId": "e995dfe4-76f7-4a20-cf48-45631fa06950"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[546.26355, 110.51968, 742.31775, 355.1156 ]], dtype=float32), array([0.9999808], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
            "To: /root/.u2net/u2net.pth\n",
            "100% 176M/176M [00:01<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa671812a90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtcGXadIvvfB"
      },
      "source": [
        "##  Define and render an example mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWCAx2s4ySuW"
      },
      "source": [
        "### Define Camera View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lus4pBNac5kQ"
      },
      "outputs": [],
      "source": [
        "# Define camera matrix C\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    FoVOrthographicCameras,\n",
        "    FoVPerspectiveCameras\n",
        ")\n",
        "device = torch.device(\"cuda:0\")\n",
        "R, T = look_at_view_transform(dist=0.6, elev=0, azim=0) # 0 elevation , and 0 azimuth\n",
        "C = FoVPerspectiveCameras(device=device, R=R, T=T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EtUttafyYSd"
      },
      "source": [
        "### Define Phong renderer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JNWSqDXSeASd"
      },
      "outputs": [],
      "source": [
        "# define renderer\n",
        "\n",
        "from pytorch3d.renderer import  (MeshRenderer, MeshRasterizer, SoftPhongShader,\n",
        "    PointLights, Materials, RasterizationSettings,BlendParams\n",
        ")\n",
        "\n",
        "def get_phong_renderer(C_init, \n",
        "                      sigma=1.0e-4, \n",
        "                      gamma=1.0e-7, \n",
        "                      faces_per_pixel=50,\n",
        "                      img_size=256,\n",
        "                       blur_radius=1):\n",
        "  \n",
        "  lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
        "\n",
        "  materials = Materials(\n",
        "    device=device,\n",
        "    specular_color=[[0.0, 0.0, 0.0]],\n",
        "    shininess=0.0)\n",
        "  \n",
        "  blend_params = BlendParams(background_color=(1,1,1), sigma=sigma, gamma=gamma)\n",
        "  if blur_radius is not 0:\n",
        "      blur_radius= np.log(1. / 1e-4 - 1.) * blend_params.sigma\n",
        "  else: blur_radius = 0\n",
        "\n",
        "  raster_settings = RasterizationSettings(\n",
        "      image_size=img_size, \n",
        "      blur_radius= blur_radius, \n",
        "      faces_per_pixel=faces_per_pixel, \n",
        "  )\n",
        "\n",
        "  r = MeshRenderer(\n",
        "      rasterizer=MeshRasterizer(\n",
        "          cameras=C_init,\n",
        "          raster_settings=raster_settings\n",
        "      ),\n",
        "      shader=SoftPhongShader(\n",
        "          device=device, \n",
        "          blend_params = blend_params,\n",
        "          cameras=C_init,\n",
        "          materials=materials,\n",
        "          lights=lights\n",
        "      )\n",
        "  )\n",
        "\n",
        "  return r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uz_l6d4yjYT"
      },
      "source": [
        "### Define Shilouette renderer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ugykXqrMym15"
      },
      "outputs": [],
      "source": [
        "def get_silhoutte_renderer(C_init, \n",
        "                      sigma=1.0e-7, \n",
        "                      gamma=1.0e-1, \n",
        "                      faces_per_pixel=50,\n",
        "                      img_size=256, \n",
        "                      blur_radius=1):\n",
        "  \n",
        "  lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
        "\n",
        "  materials = Materials(\n",
        "    device=device,\n",
        "    specular_color=[[0.0, 0.0, 0.0]],\n",
        "    shininess=0.0)\n",
        "  \n",
        "  blend_params = BlendParams(background_color=(1,1,1), sigma=sigma, gamma=gamma)\n",
        "  if blur_radius is not 0:\n",
        "    blur_radius= np.log(1. / 1e-4 - 1.) * blend_params.sigma\n",
        "  else: blur_radius = 0\n",
        "\n",
        "  raster_settings = RasterizationSettings(\n",
        "      image_size=img_size, \n",
        "      blur_radius=blur_radius, \n",
        "      faces_per_pixel=faces_per_pixel, \n",
        "  )\n",
        "\n",
        "  r = MeshRenderer(\n",
        "      rasterizer=MeshRasterizer(\n",
        "          cameras=C_init, \n",
        "          raster_settings=raster_settings\n",
        "      ),\n",
        "      shader=SoftSilhouetteShader(blend_params=blend_params)\n",
        "  )\n",
        "\n",
        "  return r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wVdF8wp0a5m"
      },
      "source": [
        "### Render Example from saved (.obj) file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "oCQoLtq2kevH",
        "outputId": "9b2b2c87-3b22-4d3b-e703-8b27ffa6dc6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa66805ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#@title Display example render via phong renderer\n",
        "obj_filename = '/content/drive/MyDrive/deca/sample_dataset/DECA_results/lewis_frame0100/lewis_frame0100.obj'\n",
        "device = torch.device(\"cuda:0\")\n",
        "mesh = load_objs_as_meshes([obj_filename], device=device)\n",
        "render = get_phong_renderer(C, sigma=1.0e-6, gamma=1.0e-7, faces_per_pixel=1, blur_radius=0) # this returns a MeshRenderer object\n",
        "I = render(mesh.to(device)).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(I[0, :, :, 0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Render example from saved FLAME parameters"
      ],
      "metadata": {
        "id": "X8tCA9vbmf_2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_1tu3yn3-7l"
      },
      "outputs": [],
      "source": [
        "#Define config (with FLAME and general parameters)\n",
        "from types import SimpleNamespace\n",
        "config = {\n",
        "    # FLAME\n",
        "    'flame_model_path': '/content/FLAME/generic_model.pkl',  # acquire it from FLAME project page\n",
        "    'flame_lmk_embedding_path': '/content/FLAME/landmark_embedding.npy',\n",
        "    'tex_space_path': '/content/FLAME_texture.npz',  # acquire it from FLAME project page\n",
        "    'n_cam': 3, # number of camera related parameters\n",
        "    'n_shape': 100, # number of shape related parameters\n",
        "    'n_exp': 50, # number of expression related parameters\n",
        "    'n_pose': 6, # number of pose related parameters\n",
        "    'n_tex': 50, # number of texture related parameters\n",
        "    'n_light': 27, # number of light related parameters\n",
        "    'useTex': True,\n",
        "    'use_face_contour': True,\n",
        "    'use_3D_translation': True,\n",
        "    'tex_type': 'BFM', # change to FLAME (maybe)\n",
        "    'tex_path': \"/content/FLAME/FLAME_albedo_from_BFM.npz\",\n",
        "    'flame_tex_path': '/content/FLAME/texture_data_256.npy',\n",
        "    'uv_size': 256,\n",
        "    'obj_filename': \"/content/FLAME/head_template.obj\",  # get the head template - to use its faces\n",
        "    'cropped_size': 256,\n",
        "    'batch_size': 1,\n",
        "    'image_size': 224,\n",
        "    'e_lr': 0.005,\n",
        "    'e_wd': 0.0001,\n",
        "    'savefolder': '/content/FLAME_results',\n",
        "    # weights of losses and reg terms\n",
        "    'w_pho': 8,\n",
        "    'w_lmks': 1,\n",
        "    'w_shape_reg': 1e-4,\n",
        "    'w_expr_reg': 1e-4,\n",
        "    'w_pose_reg': 0,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdcBtYkmykXW"
      },
      "source": [
        "## Get Image Pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtO_3nW6AuRT"
      },
      "source": [
        "### Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wHJ8-3DwAyw3"
      },
      "outputs": [],
      "source": [
        "# auxiliary function: get render and ground truth images\n",
        "from pytorch3d.transforms import axis_angle_to_matrix\n",
        "from pytorch3d.structures import Meshes\n",
        "def get_image_pair(prediction_path, data_path, frame_num, renderer, flame_model,\n",
        "                   flameTex_model, T_uv=None, F_uv=None, verts_uvs=None,\n",
        "                    pose=None, shape=None, exp=None, scale=0.3, silh=False, skip_gt=False):\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  img_size = 256\n",
        "  name = str(data_path.split(\"/\")[-1]) #e.g lewis\n",
        "  img_gt_path = os.path.join(data_path, name + '_frame%04d.jpg' % frame_num)\n",
        "  if not skip_gt:\n",
        "    try:\n",
        "      I_gt = load_img(img_path=img_gt_path, background_remove=True, scale=scale, img_size=img_size, cropped=True).to(device)\n",
        "    except:\n",
        "      print(\"Could not load ground truth image\")\n",
        "  else:\n",
        "     I_gt = np.zeros((img_size, img_size, 3))\n",
        "    \n",
        "  # Use FLAME mesh\n",
        "  #V, _, _ = flame_model.forward( shape_params=axis_angle_to_matrix(shape),\n",
        "  # expression_params=axis_angle_to_matrix(exp), pose_params=axis_angle_to_matrix(pose),\n",
        "  # eye_pose_params=None) # returns vertices, landmarks2d and landmarks3D\n",
        "\n",
        "  #T = TexturesUV(maps=T_uv, faces_uvs=F_uv, verts_uvs=V_uv)\n",
        "  #mesh = Meshes(V, F, T)\n",
        "\n",
        "  '''\n",
        "  # or just load your own (initial DECA mesh)\n",
        "  obj_filename = os.path.join(os.path.join(prediction_path, name+ '_frame%04d' % frame_num) ,  name+ '_frame%04d.obj' % frame_num)\n",
        "  mesh = load_objs_as_meshes([obj_filename], device=device)\n",
        "  '''\n",
        "\n",
        "  ### Use FLAMETex\n",
        "  texture = flameTex_model.forward(texcode)\n",
        "\n",
        "  '''\n",
        "        texcode: [batchsize, n_tex]\n",
        "        texture: [bz, 3, 256, 256], range: 0-1\n",
        "        '''\n",
        "  #mesh = Meshes (V, F, T)\n",
        "  R, T = look_at_view_transform(dist=1, elev=0, azim=0)\n",
        "  I_pred = renderer(mesh)  # pass it to the pytorch render\n",
        "\n",
        "  if silh:\n",
        "    I_gt = I_gt[:, :, :, 2]\n",
        "    I_gt[I_gt==1] = 0\n",
        "    I_gt[I_gt!=0] = 1\n",
        "    I_pred = I_pred[:, :, :, 3]\n",
        "  else:\n",
        "    I_pred = I_pred[:, :, :, 0:3]\n",
        "    \n",
        "  return I_pred, I_gt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGdnGFs9BCSI"
      },
      "source": [
        "### Display training image pairs e.g GT & Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "WH_AQhWNizF2",
        "outputId": "f0541ef9-b2a8-4441-e63f-5a126cfb01eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f5743d288005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m I_pred, I_gt = get_image_pair(prediction_path=prediction_path, data_path=data_path,\n\u001b[0;32m---> 11\u001b[0;31m                               frame_num=frame_num, renderer=renderer_phong, silh=False)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mI_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mI_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_gt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_image_pair() missing 2 required positional arguments: 'flame_model' and 'flameTex_model'"
          ]
        }
      ],
      "source": [
        "R, T = look_at_view_transform(dist=0.65, elev=0, azim=0) # 0 elevation , and 0 azimuth\n",
        "C = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "renderer_phong = get_phong_renderer(C, sigma=1.0e-7, gamma=1.0e-7, \n",
        "                                    faces_per_pixel=1, img_size=256)\n",
        "\n",
        "frame_num = 7\n",
        "prediction_path = \"/content/drive/MyDrive/deca/sample_dataset/DECA_results\" #path to folder with DECA predictions\n",
        "data_path = \"/content/drive/MyDrive/deca/sample_dataset/lewis\" # path to folder with GT frames\n",
        "\n",
        "I_pred, I_gt = get_image_pair(prediction_path=prediction_path, data_path=data_path,\n",
        "                              frame_num=frame_num, renderer=renderer_phong, silh=False)\n",
        "I_merged = torch.cat([ I_pred, I_gt], 2)[0].detach().cpu()\n",
        "plt.figure(figsize=(10, 20))\n",
        "plt.imshow(I_merged) #matplot displays background color as black"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save GT images (after background removal -  Time efficient)"
      ],
      "metadata": {
        "id": "6rULRNhSfi0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/sample_dataset/lewis\"\n",
        "for frame in os.listdir(data_path):\n",
        "  path = os.path.join(data_path, frame)\n",
        "  img = load_img(path, background_remove=True, replace=True, scale=0.3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09uQRHgOfeD4",
        "outputId": "3f5e3a16-fd4a-41dd-a96a-afcd21c4679a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[594.283  ,  97.60013, 789.3781 , 343.1941 ]], dtype=float32), array([1.], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[614.09344,  88.5514 , 801.59296, 337.67157]], dtype=float32), array([0.99998], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[629.51764,  77.06354, 817.79205, 321.37314]], dtype=float32), array([0.99996483], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[623.9287  ,  73.925644, 814.3875  , 321.89197 ]], dtype=float32), array([0.99996006], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[605.3798 ,  73.12203, 801.58777, 327.46674]], dtype=float32), array([0.99999464], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[506.6942 , 130.43262, 709.53644, 379.62604]], dtype=float32), array([0.99999404], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[501.9244 , 124.44722, 704.0479 , 375.56952]], dtype=float32), array([0.9999833], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(None, array([None], dtype=object))\n",
            "No face is detected\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[617.5516 ,  78.71306, 811.065  , 324.75476]], dtype=float32), array([0.9999988], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[102.95941, 100.61935, 156.48026, 157.14487]], dtype=float32), array([0.9999896], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[616.3351 ,  75.40991, 812.86896, 341.19608]], dtype=float32), array([0.99999774], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[106.11952 , 101.443565, 153.85262 , 156.11336 ]], dtype=float32), array([0.9999999], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[601.50336,  74.31641, 795.2296 , 325.17505]], dtype=float32), array([0.9999858], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[577.9062 ,  80.87115, 783.04407, 345.4026 ]], dtype=float32), array([0.9999976], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[619.9591 ,  75.55774, 809.3587 , 322.31128]], dtype=float32), array([0.99999964], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[618.3038 ,  77.70473, 811.42957, 325.5806 ]], dtype=float32), array([0.99999905], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[613.15375,  78.21467, 806.74866, 337.79675]], dtype=float32), array([0.9999989], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[103.80241,  98.70446, 154.0122 , 154.70995]], dtype=float32), array([0.9999939], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[510.25024, 126.48966, 706.76685, 372.08557]], dtype=float32), array([0.99993813], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[618.7042 ,  76.18724, 827.8628 , 338.8557 ]], dtype=float32), array([0.99999654], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[604.94165,  88.99237, 795.66565, 340.86835]], dtype=float32), array([0.99994123], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[562.7773  , 108.134094, 755.0154  , 349.57755 ]], dtype=float32), array([0.9999968], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[625.9209  ,  83.439255, 814.96704 , 326.01746 ]], dtype=float32), array([0.999977], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[607.9438 ,  93.52545, 794.5547 , 341.34253]], dtype=float32), array([0.99998045], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[619.3479 ,  76.92081, 826.60535, 341.734  ]], dtype=float32), array([0.9999976], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[592.9317 ,  76.58221, 787.35626, 326.56976]], dtype=float32), array([0.99998283], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[549.9048 , 105.55462, 745.25116, 352.62003]], dtype=float32), array([0.99993646], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[546.26355, 110.51968, 742.31775, 355.1156 ]], dtype=float32), array([0.9999808], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[607.5824 ,  92.84837, 794.89655, 341.43256]], dtype=float32), array([0.9999808], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[579.0535 ,  94.27215, 774.4237 , 342.22037]], dtype=float32), array([0.9999871], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[613.1763 ,  78.47482, 807.83124, 337.5182 ]], dtype=float32), array([0.9999993], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[506.00522, 137.13356, 708.03784, 385.84744]], dtype=float32), array([0.99998736], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[624.302  ,  78.84235, 827.7349 , 337.09653]], dtype=float32), array([0.9999995], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[618.43787,  80.59208, 810.5344 , 334.3913 ]], dtype=float32), array([0.9999995], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[506.6354 , 130.68427, 709.8865 , 378.8479 ]], dtype=float32), array([0.9999943], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[593.21136,  81.33963, 786.571  , 328.35498]], dtype=float32), array([0.99999964], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[580.71423,  86.27055, 778.5466 , 342.77704]], dtype=float32), array([0.99999726], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[539.3447  , 108.003204, 735.9418  , 354.4581  ]], dtype=float32), array([0.99999666], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[605.494  ,  89.05556, 795.76416, 340.40036]], dtype=float32), array([0.99994135], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[531.4255 , 113.42876, 725.8395 , 362.37183]], dtype=float32), array([0.99991465], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[593.7143 ,  82.76804, 786.0055 , 329.96667]], dtype=float32), array([0.99999976], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[103.975395,  97.3418  , 156.23741 , 156.66527 ]], dtype=float32), array([0.9999988], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[575.6438 ,  93.92325, 770.36035, 343.50912]], dtype=float32), array([0.9998908], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[ 94.55416 ,  95.793564, 154.95255 , 159.04742 ]], dtype=float32), array([0.9999808], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[102.46463 , 101.894066, 153.97737 , 159.89879 ]], dtype=float32), array([0.99809307], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[102.447495,  98.29403 , 155.08011 , 156.9126  ]], dtype=float32), array([0.9999963], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[615.8288 ,  74.6831 , 812.2716 , 340.40436]], dtype=float32), array([0.99999714], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[101.535736,  97.007614, 150.60265 , 155.03181 ]], dtype=float32), array([0.9914415], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[620.64404,  75.81856, 828.01117, 336.4321 ]], dtype=float32), array([0.99999857], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[627.02185 ,  76.238525, 816.4328  , 321.75342 ]], dtype=float32), array([0.9999759], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n",
            "(array([[567.5549 ,  97.08766, 767.9157 , 349.69974]], dtype=float32), array([0.9999918], dtype=float32))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/sample_data/temp2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfc-YWSR2lAv"
      },
      "source": [
        "### Generate training renders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVlF5ra6joFA"
      },
      "outputs": [],
      "source": [
        "render_log_dir = '/content/renders'\n",
        "!rm -rf $render_log_dir\n",
        "!mkdir $render_log_dir\n",
        "\n",
        "path_to_objs = \"/content/drive/MyDrive/deca/sample_dataset/DECA_results/\"\n",
        "frames = 200\n",
        "prediction_path = path_to_objs\n",
        "for frame in range(0, frames):\n",
        "  I_pred, I_gt = get_image_pair(prediction_path=prediction_path, data_path=data_path,\n",
        "                              frame_num=frame, renderer=renderer_phong, silh=False, skip_gt=True)\n",
        "  I_pred = get_render(prediction_path=prediction_path, frame_num, renderer=renderer_phong, params)\n",
        "  \n",
        "  render = I_pred.detach().cpu().squeeze(0).numpy()\n",
        "  savepath = os.path.join(render_log_dir,'_frame%04d.png' % frame)\n",
        "  plt.imsave(savepath, render)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function to get DECA renders\n",
        "import sys\n",
        "sys.path.append(\"/content/smplx/\")\n",
        "from smplx.FLAME import FLAME\n",
        "from smplx.FLAME import FLAMETex\n",
        "from pytorch3d.transforms import axis_angle_to_matrix\n",
        "from pytorch3d.structures import load_obj\n",
        "\n",
        "config = SimpleNamespace(**config) # to access dictionary keys with dot\n",
        "\n",
        "flame_model = FLAME(config) # this is the FLAME model for the shape, pose, etc.\n",
        "tex_flame_model = FLAMETex(config) # this is the FLAME model for texture\n",
        "batch_size = 1\n",
        "def get_render(prediction_path, frame_num, renderer, params):\n",
        "  codedict = flame_deca_config\n",
        "  vertices, landmarks2d, landmarks3d = flame_model(shape_params=codedict['shape'], expression_params=codedict['exp'], pose_params=codedict['pose'])\n",
        "  if config.use_tex:\n",
        "            albedo = tex_flame_model(codedict['tex'])\n",
        "  else:\n",
        "      albedo = torch.zeros([batch_size, 3, config.uv_size, config.uv_size], device=device) \n",
        "  landmarks3d_world = landmarks3d.clone()\n",
        "\n",
        "\n",
        "  opdict = {\n",
        "      \"verts\": vertices\n",
        "  }\n",
        "\n",
        "  # Get also faces\n",
        "  verts, faces, aux = load_obj(config.obj_filename) # faces will be the same with the head template\n",
        "  uvcoords = aux.verts_uvs[None, ...]      # (N, V, 2)\n",
        "  uvfaces = faces.textures_idx[None, ...] # (N, F, 3)\n",
        "  faces = faces.verts_idx[None,...]\n",
        "\n",
        "  # Get texture uv\n",
        "\n",
        "\n",
        "  '''\n",
        "  vertices: [nv, 3], tensor\n",
        "  texture: [3, h, w], tensor\n",
        "  '''\n",
        "  i = 0\n",
        "  vertices = opdict['verts'][i].cpu().numpy()\n",
        "  faces = faces[0].cpu().numpy()\n",
        "  #texture = util.tensor2image(opdict['uv_texture_gt'][i])\n",
        "  #uvcoords = self.render.raw_uvcoords[0].cpu().numpy()\n",
        "  #uvfaces = self.render.uvfaces[0].cpu().numpy()\n",
        "  # save coarse mesh, with texture and normal map\n",
        "  normal_map = util.tensor2image(opdict['uv_detail_normals'][i]*0.5 + 0.5)\n",
        "  util.write_obj(filename, vertices, faces, \n",
        "                  texture=texture, \n",
        "                  uvcoords=uvcoords, \n",
        "                  uvfaces=uvfaces, \n",
        "                  normal_map=normal_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "VjFEFQD8qoSl",
        "outputId": "b4601206-4298-4380-a7c5-83b56163a852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1085ad5ada73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/smplx/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msmplx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAME\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFLAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msmplx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAME\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFLAMETex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maxis_angle_to_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'smplx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUsJ3e7YAPrl"
      },
      "source": [
        "### Visualize Training renders (DECA results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riOwh5CiKVDk"
      },
      "outputs": [],
      "source": [
        "# Visualize training renders (DECA predictions)\n",
        "%cd /content/renders\n",
        "!ffmpeg -framerate 20 -pattern_type glob -i '*.png' -vcodec h264 -pix_fmt yuv420p -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\"  /content/training_data.mp4\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suSqxy9u0lln"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('training_data.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLXQU3DJ2Lbt"
      },
      "source": [
        "## Optimization/Training of FLAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_JynC_2v2Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7469223e-3cd6-42a9-c60e-ec08bae3e929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating the FLAME Decoder\n"
          ]
        }
      ],
      "source": [
        "sys.path.append(\"/content/smplx/\")\n",
        "from smplx.FLAME import FLAME\n",
        "from smplx.FLAME import FLAMETex\n",
        "#from FLAME import FLAMETex\n",
        "#from smplx.body_models import FLAMELayer\n",
        "#from body_models import FLAME\n",
        "from pytorch3d.transforms import axis_angle_to_matrix\n",
        "\n",
        "#!mv  '/content/FLAME/generic_model.pkl' \"/content/FLAME/FLAME_NEUTRAL.pkl\"\n",
        "FLAME_model_path = '/content/FLAME/'\n",
        "FLAME_uv_map_path = '/content/drive/MyDrive/deca/sample_dataset/DECA_results/lewis_frame0000/lewis_frame0000.obj'\n",
        "#config[\"flame_tex_path\"] = FLAME_uv_map_path\n",
        "\n",
        "config = SimpleNamespace(**config) # to access dictionary keys with dot\n",
        "\n",
        "flame_model = FLAME(config) # this is the FLAME model for the shape, pose, etc.\n",
        "tex_flame_model = FLAMETex(config) # this is the FLAME model for texture\n",
        "\n",
        "# texture map\n",
        "_, faces, properties = load_obj(FLAME_uv_map_path, load_textures=True)\n",
        "V_uv = properties.verts_uvs.unsqueeze(0).to(device)\n",
        "F_uv = faces.textures_idx.unsqueeze(0).type(torch.long).to(device)\n",
        "T_uv = torch.ones([1, 256, 256, 3]).to(device) # blank one\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UxqT543DkVv"
      },
      "outputs": [],
      "source": [
        "rgb_log_dir = '/content/logs_phong_optimisation'\n",
        "!rm -rf $rgb_log_dir\n",
        "!mkdir $rgb_log_dir\n",
        "\n",
        "\n",
        "### General parameters\n",
        "max_frame = 40 # number of available training frames\n",
        "img_size = 256 # image dimension of each training frame - SHOULD MATCH render (image) dimension\n",
        "n_epochs = 50\n",
        "prediction_path = \"/content/sample_dataset/DECA_results\" #path to folder with DECA predictions\n",
        "data_path = \"/content/sample_dataset/lewis\" # path to folder with GT frames\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Define phong renderer\n",
        "R, T = look_at_view_transform(dist=0.65, elev=0, azim=0) # 0 elevation , and 0 azimuth\n",
        "C = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
        "renderer_phong = get_phong_renderer(C, sigma=1.0e-7, gamma=1.0e-7, \n",
        "                                    faces_per_pixel=1, img_size=img_size)\n",
        "\n",
        "\n",
        "### Initialize FLAME optimization parameters 0\n",
        "shape = torch.nn.Parameter(torch.zeros(img_size, config[\"shape_params\"]).float().to(device), requires_grad=True)\n",
        "tex = torch.nn.Parameter(torch.zeros(img_size, config[\"tex_params\"]).float().to(device), requires_grad=True)\n",
        "exp = torch.nn.Parameter(torch.zeros(img_size, config[\"expression_params\"]).float().to(device), requires_grad=True)\n",
        "pose = torch.nn.Parameter(torch.zeros(img_size, config[\"pose_params\"]).float().to(device), requires_grad=True)\n",
        "cam = torch.zeros(img_size, config[\"camera_params\"]); cam[:, 0] = 5.\n",
        "cam = torch.nn.Parameter(cam.float().to(device), requires_grad=True)\n",
        "lights = torch.nn.Parameter(torch.zeros(img_size, 9, 3).float().to(device), requires_grad=True)\n",
        "\n",
        "### Initialize FLAME parameters with DECA results\n",
        "shape = torch.nn.Parameter(flame_deca_config[\"shape\"], requires_grad=True)\n",
        "tex = torch.nn.Parameter(flame_deca_config[\"tex\"], requires_grad=True)\n",
        "exp = torch.nn.Parameter(flame_deca_config[\"exp\"], requires_grad=True)\n",
        "pose = torch.nn.Parameter(flame_deca_config[\"pose\"], requires_grad=True)\n",
        "cam = torch.nn.Parameter(flame_deca_config[\"cam\"], requires_grad=True)\n",
        "lights = torch.nn.Parameter(flame_deca_config[\"light\"], requires_grad=True)\n",
        "\n",
        "\n",
        "\n",
        "### Initialize Texture optimization parameters\n",
        "_, faces, properties = load_obj(FLAME_uv_map_path, load_textures=False) # set to False\n",
        "V_uv = properties.verts_uvs.unsqueeze(0).to(device)\n",
        "F_uv = faces.textures_idx.unsqueeze(0).type(torch.long).to(device)\n",
        "texture_map_path = str(FLAME_uv_map_path.split(\".\")[:-1][0])+ \".png\"\n",
        "texture_map = np.asarray(Image.open(texture_map_path).convert(\"RGB\"))\n",
        "T_uv = torch.Tensor(texture_map).unsqueeze(0).to(device) # texture map is 1xHxWxChannels\n",
        "T_uv = torch.nn.Parameter(T_uv, requires_grad=True) # texture - requires_grad is True by default\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Optimizers\n",
        "face_opt = torch.optim.Adam([shape, tex, exp, pose, lights, cam], lr=2.0e-4)# face optimization\n",
        "face_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(face_opt, \n",
        "                                            patience=2, verbose=True) # adjust learning rate\n",
        "uv_opt = torch.optim.Adam([T_uv], lr=1.0e-2) # texture optimization uv map\n",
        "uv_scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(uv_opt, \n",
        "                                                         patience=2,\n",
        "                                                         verbose=True)\n",
        "\n",
        "crit = torch.nn.L1Loss() # L1 loss for optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dump"
      ],
      "metadata": {
        "id": "iO5dHYQkAXzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"/content/FLAME/generic_model.pkl\", \"rb\") as f:\n",
        "  flame_model = pickle.load(f, encoding='latin1')"
      ],
      "metadata": {
        "id": "zObhhsVyWIPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tx = np.load(\"/content/texture_data_256.npy\", allow_pickle=True, encoding='latin1')"
      ],
      "metadata": {
        "id": "X3cC8KDvkvrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tx[()].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOCfiFj6msya",
        "outputId": "c30a6845-0126-410d-b765-ca8fed6b056d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['img_size', 'ft', 'valid_pixel_b_coords', 'f', 'vt', 'y_coords', 'valid_pixel_ids', 'valid_pixel_3d_faces', 'x_coords'])"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flame_model.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSaHMr3LW53g",
        "outputId": "95058e61-1fa6-44c5-b976-d9bd65360869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['f', 'J_regressor', 'kintree_table', 'J', 'bs_style', 'weights', 'posedirs', 'v_template', 'shapedirs', 'bs_type'])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.load(\"/content/landmark_embedding.npy\", allow_pickle=True, encoding='latin1')\n",
        "a = a[()]"
      ],
      "metadata": {
        "id": "cP-0Rq2WS3WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flame_params_path = \"/content/drive/MyDrive/deca/sample_dataset/DECA_results/lewis_frame0001/flame_params.pkl\"\n",
        "import pickle as pkl\n",
        "with open(flame_params_path, \"rb\") as f:\n",
        "  flame_deca_config = pkl.load(f)"
      ],
      "metadata": {
        "id": "uExpmmL3KvSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ_uI_lmEJsb"
      },
      "source": [
        "### Texture Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL2H3fRyrk6k"
      },
      "outputs": [],
      "source": [
        "for epoch_id in range(0, n_epochs):\n",
        "  I_pred, I_gt = get_image_pair(prediction_path=prediction_path, data_path=data_path,\n",
        "                              frame_num=1, renderer=renderer_phong, silh=False)\n",
        "  I_merged = torch.cat([I_pred, I_gt], 2)[0].detach().cpu().clip(0, 1).numpy()\n",
        "  plt.imsave(os.path.join(rgb_log_dir, '%04d.png' % epoch_id), I_merged)\n",
        "\n",
        "  train_frames = np.random.randint(low=0, high=max_frame, size=(5))#max_frame))\n",
        "\n",
        "  total_loss = 0 # initial loss is 0 \n",
        "\n",
        "  for frame_num in train_frames:\n",
        "\n",
        "    I_pred, I_gt = get_image_pair(prediction_path=prediction_path, data_path=data_path,\n",
        "                              frame_num=frame_num, renderer=renderer_phong, silh=False)\n",
        "\n",
        "    loss = crit(I_gt.to(device), I_pred.to(device))\n",
        "    loss.requires_grad = True\n",
        "    total_loss += float(loss)\n",
        "\n",
        "    face_opt.zero_grad()\n",
        "    uv_opt.zero_grad()\n",
        "    loss.backward()\n",
        "    uv_opt.step()\n",
        "    face_opt.step()\n",
        "\n",
        "  print(\"Total L1 loss: %f\" % total_loss)\n",
        "  face_scheduler.step(total_loss)\n",
        "  uv_scheduler.step(total_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yotHmitFa2k"
      },
      "outputs": [],
      "source": [
        "# @title generate texture optimisation video\n",
        "%cd /content/logs_phong_optimisation\n",
        "!ffmpeg -framerate 1 -pattern_type glob -i '*.png' -vcodec h264 -pix_fmt yuv420p -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\"  /content/texture_optimisation.mp4\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egDdvlHILXWe"
      },
      "outputs": [],
      "source": [
        "# @title Show texture optimisation process\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('texture_optimisation.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SFHf97nDwV0A",
        "Wp37N2qpqcbR",
        "ZIxi6ou1qv6v",
        "o1CG5ze_weMZ",
        "czaLoYwnwnp7",
        "y9G9D7KezshV",
        "FtcGXadIvvfB",
        "bWCAx2s4ySuW",
        "-EtUttafyYSd",
        "-uz_l6d4yjYT",
        "0wVdF8wp0a5m",
        "hdcBtYkmykXW",
        "FtO_3nW6AuRT",
        "6rULRNhSfi0n",
        "jfc-YWSR2lAv",
        "CUsJ3e7YAPrl",
        "ZLXQU3DJ2Lbt",
        "iO5dHYQkAXzT",
        "DQ_uI_lmEJsb"
      ],
      "name": "fit_FLAME_mesh.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}