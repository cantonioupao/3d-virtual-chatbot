{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "depthmap_training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eSM5J6c7nFEG",
        "7l4XdAf2nNIs",
        "CBb3Rl7sRTYK",
        "Tn9pFIq5iCQR",
        "s5dQFS9tiLy8",
        "KV-1gpB2s10l",
        "_fl7cO9QLiRB"
      ],
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Model\n",
        "This is the regression model that is trained to predict accurate depth maps (e.g 128,128) from single input RGB images (e.g 512. 512, 3). A set of experiments takes place, in this notebook. In summary:\n",
        "\n",
        "*   Define X (Input Images) and Y (GT-depth maps) data\n",
        "*   Select Depth Regression Network Architecture\n",
        "*   Train Model for a number of initial samples\n",
        "*   Test on random sample/example\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H5P1zQO3mEQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Define the path to the dataset for the input data and the ground truth depth maps. Load everything to the dataset."
      ],
      "metadata": {
        "id": "eSM5J6c7nFEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3CX6O41El4fm"
      },
      "outputs": [],
      "source": [
        "input_data_path = '/content/drive/MyDrive/datasets/eg3d/images/' #@param\n",
        "gt_data_path = '/content/drive/MyDrive/datasets/eg3d/depth128x128/' #@param"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture (Option 1)\n",
        "The initial selection is the MiDaS pretrained model on monocular depth map estimation. The official repository can be found [here](https://github.com/isl-org/MiDaS) "
      ],
      "metadata": {
        "id": "7l4XdAf2nNIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/isl-org/MiDaS\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hfe1uHIrZ5A",
        "outputId": "723f8f14-3043-4bb2-be85-541da163bbbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MiDaS'...\n",
            "remote: Enumerating objects: 501, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 501 (delta 70), reused 53 (delta 53), pack-reused 408\u001b[K\n",
            "Receiving objects: 100% (501/501), 414.26 KiB | 9.21 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.5-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model for HQ depth maps\n",
        "model_path = '/content/MiDaS/weights/dpt_large-midas-2f21e586.pt'\n",
        "!wget https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt -O {model_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a15WLktrmay",
        "outputId": "ce11c9ce-c5a3-4412-b90e-d8d79ca1eb53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-13 15:54:36--  https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/isl-org/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt [following]\n",
            "--2022-07-13 15:54:36--  https://github.com/isl-org/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/350409920/3568d880-8b45-11eb-8c45-12766a421e43?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220713%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220713T155436Z&X-Amz-Expires=300&X-Amz-Signature=527438c7d45cfce0b409262dcd3934977d0c0ae57c1d4e83868043389b446b23&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350409920&response-content-disposition=attachment%3B%20filename%3Ddpt_large-midas-2f21e586.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-07-13 15:54:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/350409920/3568d880-8b45-11eb-8c45-12766a421e43?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220713%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220713T155436Z&X-Amz-Expires=300&X-Amz-Signature=527438c7d45cfce0b409262dcd3934977d0c0ae57c1d4e83868043389b446b23&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350409920&response-content-disposition=attachment%3B%20filename%3Ddpt_large-midas-2f21e586.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1376378527 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘/content/MiDaS/weights/dpt_large-midas-2f21e586.pt’\n",
            "\n",
            "/content/MiDaS/weig 100%[===================>]   1.28G   276MB/s    in 4.8s    \n",
            "\n",
            "2022-07-13 15:54:41 (273 MB/s) - ‘/content/MiDaS/weights/dpt_large-midas-2f21e586.pt’ saved [1376378527/1376378527]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture (Option 2)\n",
        "Another option for a model architecture is the PIFU model architecture. "
      ],
      "metadata": {
        "id": "CBb3Rl7sRTYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIFUHD\n",
        "It is a bit more complex, but it can be found [here](https://github.com/facebookresearch/pifuhd)"
      ],
      "metadata": {
        "id": "Tn9pFIq5iCQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/pifuhd\n",
        "%cd /content/pifuhd/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfq-ddRGUspb",
        "outputId": "645577d4-a9fe-4d1c-c45b-b1ad0af3c168"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'pifuhd' already exists and is not an empty directory.\n",
            "/content/pifuhd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained weights for model\n",
        "model_path = '/content/pifuhd/pifuhd.pt'\n",
        "!wget \"https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\" -O {model_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0Ts7AE7W72K",
        "outputId": "17705c0a-e82a-47a6-8d05-5cd66e84c5d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-13 16:20:58--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘/content/pifuhd/pifuhd.pt’\n",
            "\n",
            "/content/pifuhd/pif 100%[===================>]   1.44G  42.1MB/s    in 37s     \n",
            "\n",
            "2022-07-13 16:21:36 (39.7 MB/s) - ‘/content/pifuhd/pifuhd.pt’ saved [1548375177/1548375177]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recon(opt, use_rect=False):\n",
        "    # load checkpoints\n",
        "    state_dict_path = None\n",
        "    if opt.load_netMR_checkpoint_path is not None:\n",
        "        state_dict_path = opt.load_netMR_checkpoint_path\n",
        "\n",
        "    print('test data size: ', len(test_dataset))\n",
        "    projection_mode = test_dataset.projection_mode\n",
        "\n",
        "    opt_netG = state_dict['opt_netG']\n",
        "    netG = HGPIFuNetwNML(opt_netG, projection_mode).to(device=cuda)\n",
        "    netMR = HGPIFuMRNet(opt, netG, projection_mode).to(device=cuda)\n",
        "\n",
        "    def set_eval():\n",
        "        netG.eval()\n",
        "\n",
        "    # load checkpoints\n",
        "    netMR.load_state_dict(state_dict['model_state_dict'])\n",
        "\n",
        "    ## test\n",
        "    with torch.no_grad():\n",
        "        set_eval()\n",
        "\n",
        "        print('generate mesh (test) ...')\n",
        "        for i in tqdm(range(start_id, end_id)):\n",
        "            if i >= len(test_dataset):\n",
        "                break\n",
        "            \n",
        "            # for multi-person processing, set it to False\n",
        "            if True:\n",
        "                test_data = test_dataset[i]\n",
        "\n",
        "                save_path = '%s/%s/recon/result_%s_%d.obj' % (opt.results_path, opt.name, test_data['name'], opt.resolution)\n",
        "\n",
        "                print(save_path)\n",
        "                gen_mesh(opt.resolution, netMR, cuda, test_data, save_path, components=opt.use_compose)\n",
        "            else:\n",
        "                for j in range(test_dataset.get_n_person(i)):\n",
        "                    test_dataset.person_id = j\n",
        "                    test_data = test_dataset[i]\n",
        "                    save_path = '%s/%s/recon/result_%s_%d.obj' % (opt.results_path, opt.name, test_data['name'], j)\n",
        "                    gen_mesh(opt.resolution, netMR, cuda, test_data, save_path, components=opt.use_compose)"
      ],
      "metadata": {
        "id": "0RZlntV6akBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIFU\n",
        "The model architecture can be found [here](https://github.com/shunsukesaito/PIFu)"
      ],
      "metadata": {
        "id": "s5dQFS9tiLy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shunsukesaito/PIFu"
      ],
      "metadata": {
        "id": "m3sz1RaViNjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "KV-1gpB2s10l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MiDaS/\n",
        "!cp /content/drive/MyDrive/datasets/eg3d/images/seed0001.png /content/MiDaS/input/\n",
        "!python run.py --model_type dpt_large # --model_weights={model_weights_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_g5VBoMs1Nf",
        "outputId": "8b7a2d26-0038-4db2-8f7e-41766cfae7c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiDaS\n",
            "initialize\n",
            "device: cuda\n",
            "start processing\n",
            "  processing input/seed0001.png (1/1)\n",
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "_fl7cO9QLiRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose\n",
        "from midas.dpt_depth import DPTDepthModel\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import utils\n",
        "import numpy as np\n",
        "import PIL\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
        "\n",
        "l1_loss = nn.L1Loss() # l1-loss\n",
        "model = DPTDepthModel(\n",
        "            path=model_path,\n",
        "            backbone=\"vitl16_384\",\n",
        "            non_negative=False,) # define model architecture with pretrained weights\n",
        "\n",
        "# Input Preprocessing\n",
        "net_w, net_h = 128, 128\n",
        "resize_mode=\"minimal\"\n",
        "normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "transform = Compose(\n",
        "    [ Resize(net_w, net_h, resize_target=None, keep_aspect_ratio=True, ensure_multiple_of=32,\n",
        "            resize_method=resize_mode, image_interpolation_method=cv2.INTER_CUBIC,), normalization,PrepareForNet(), ])\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "model.train() # set in train mode\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
        "                                            patience=10, verbose=True)\n",
        "\n",
        "# trained_model = model.load_state_dict(torch.load(final_weights_path)) # load the final training weights"
      ],
      "metadata": {
        "id": "-GeKps-X9BOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create list with GT and input data paths\n",
        "batch_size = 5\n",
        "img_train = []\n",
        "gt_train = []\n",
        "for img in os.listdir(input_data_path):\n",
        "    filepath = os.path.join(input_data_path, img)\n",
        "    gt_path = os.path.join(gt_data_path, img)\n",
        "    img_train.append(filepath)\n",
        "    gt_train.append(gt_path)\n",
        "\n",
        "\n",
        "img_train = [img_train[i:i + batch_size] for i in range(0, len(img_train), )]\n",
        "gt_train = [gt_train[i:i+batch_size] for i in range(0, len(gt_train), batch_size)]"
      ],
      "metadata": {
        "id": "eilqVTwWLITf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Function to normalize depth\n",
        "def normalize_depth(array : np.array):\n",
        "  maxx = np.amax(array)\n",
        "  minx = np.amin(array)\n",
        "  x = 2 * ((array - minx) / (maxx - minx) ) - 1\n",
        "  return np.array(x, dtype=np.float32)\n",
        "\n",
        "\n",
        "def normalize_depth_torch(tensor : torch):\n",
        "  maxx = torch.amax(tensor)\n",
        "  minx = torch.amin(tensor)\n",
        "  x = 2 * ((tensor - minx) / (maxx - minx) ) - 1\n",
        "  return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wjswTpny4E1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Check Model parameters\n",
        "p =  []\n",
        "for name, param in model.named_parameters():\n",
        "  if name == 'pretrained.model.patch_embed.proj.weight':\n",
        "    a_param = param.detach().cpu().numpy()  "
      ],
      "metadata": {
        "id": "7tzFI45-FQzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training Skeleton\n",
        "trainX = img_train[0:200] # first 5 batches\n",
        "trainY = gt_train[0:200]\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    total_loss = 0.0\n",
        "    for i, batch in enumerate(trainX):\n",
        "      inputs = [] # batch inputs\n",
        "      gts = [] # batch labels/gt data\n",
        "      for filepath in batch:\n",
        "        gt_np = np.array(PIL.Image.open(gt_path))\n",
        "        img = utils.read_image(filepath)\n",
        "        img_input = transform({\"image\": img})[\"image\"]\n",
        "        input = torch.from_numpy(img_input).to(device).unsqueeze(0)\n",
        "        gt_np = normalize_depth(gt_np)\n",
        "        gt = torch.tensor(gt_np, requires_grad=True).to(device).unsqueeze(0)\n",
        "        gts.append(gt)\n",
        "        inputs.append(input)\n",
        "\n",
        "      # Convert list to batch tensor\n",
        "      gts = torch.cat(gts)\n",
        "      inputs = torch.cat(inputs)\n",
        "\n",
        "      # Per batch loss and update\n",
        "      predictions = model(inputs)\n",
        "      predictions = normalize_depth_torch(predictions)\n",
        "      loss = l1_loss(gts, predictions)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += float(loss)\n",
        "\n",
        "    print(\"e\", str(epoch),\"- Total L1 loss: %f\" %total_loss)\n",
        "    lr_scheduler.step(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcVOeOPUMqMI",
        "outputId": "f22775ce-f1d8-4be3-dab6-062c9e0fe972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e 1 - Total L1 loss: 1.819955\n",
            "e 2 - Total L1 loss: 1.786839\n",
            "Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.\n",
            "e 3 - Total L1 loss: 1.766926\n",
            "e 4 - Total L1 loss: 1.764382\n",
            "e 5 - Total L1 loss: 1.761886\n",
            "e 6 - Total L1 loss: 1.759425\n",
            "e 7 - Total L1 loss: 1.756995\n",
            "e 8 - Total L1 loss: 1.754597\n",
            "Epoch 00021: reducing learning rate of group 0 to 1.0000e-06.\n",
            "e 9 - Total L1 loss: 1.752976\n",
            "e 10 - Total L1 loss: 1.752809\n",
            "e 11 - Total L1 loss: 1.752643\n",
            "e 12 - Total L1 loss: 1.752477\n",
            "e 13 - Total L1 loss: 1.752311\n",
            "e 14 - Total L1 loss: 1.752145\n",
            "Epoch 00027: reducing learning rate of group 0 to 1.0000e-07.\n",
            "e 15 - Total L1 loss: 1.752034\n",
            "e 16 - Total L1 loss: 1.752028\n",
            "e 17 - Total L1 loss: 1.752023\n",
            "e 18 - Total L1 loss: 1.752017\n",
            "e 19 - Total L1 loss: 1.752012\n",
            "e 20 - Total L1 loss: 1.752006\n",
            "Epoch 00033: reducing learning rate of group 0 to 1.0000e-08.\n",
            "e 21 - Total L1 loss: 1.752003\n",
            "e 22 - Total L1 loss: 1.752002\n",
            "e 23 - Total L1 loss: 1.752002\n",
            "e 24 - Total L1 loss: 1.752002\n",
            "e 25 - Total L1 loss: 1.752002\n",
            "e 26 - Total L1 loss: 1.752002\n",
            "e 27 - Total L1 loss: 1.752002\n",
            "e 28 - Total L1 loss: 1.752002\n",
            "e 29 - Total L1 loss: 1.752002\n",
            "e 30 - Total L1 loss: 1.752002\n",
            "e 31 - Total L1 loss: 1.752002\n",
            "e 32 - Total L1 loss: 1.752002\n",
            "e 33 - Total L1 loss: 1.752002\n",
            "e 34 - Total L1 loss: 1.752002\n",
            "e 35 - Total L1 loss: 1.752002\n",
            "e 36 - Total L1 loss: 1.752001\n",
            "e 37 - Total L1 loss: 1.752001\n",
            "e 38 - Total L1 loss: 1.752001\n",
            "e 39 - Total L1 loss: 1.752001\n",
            "e 40 - Total L1 loss: 1.752001\n",
            "e 41 - Total L1 loss: 1.752001\n",
            "e 42 - Total L1 loss: 1.752001\n",
            "e 43 - Total L1 loss: 1.752001\n",
            "e 44 - Total L1 loss: 1.752001\n",
            "e 45 - Total L1 loss: 1.752001\n",
            "e 46 - Total L1 loss: 1.752001\n",
            "e 47 - Total L1 loss: 1.752001\n",
            "e 48 - Total L1 loss: 1.752001\n",
            "e 49 - Total L1 loss: 1.752000\n",
            "e 50 - Total L1 loss: 1.752000\n",
            "e 51 - Total L1 loss: 1.752000\n",
            "e 52 - Total L1 loss: 1.752000\n",
            "e 53 - Total L1 loss: 1.752000\n",
            "e 54 - Total L1 loss: 1.752000\n",
            "e 55 - Total L1 loss: 1.752000\n",
            "e 56 - Total L1 loss: 1.752000\n",
            "e 57 - Total L1 loss: 1.752000\n",
            "e 58 - Total L1 loss: 1.752000\n",
            "e 59 - Total L1 loss: 1.752000\n",
            "e 60 - Total L1 loss: 1.752000\n",
            "e 61 - Total L1 loss: 1.752000\n",
            "e 62 - Total L1 loss: 1.752000\n",
            "e 63 - Total L1 loss: 1.752000\n",
            "e 64 - Total L1 loss: 1.752000\n",
            "e 65 - Total L1 loss: 1.751999\n",
            "e 66 - Total L1 loss: 1.751999\n",
            "e 67 - Total L1 loss: 1.751999\n",
            "e 68 - Total L1 loss: 1.751999\n",
            "e 69 - Total L1 loss: 1.751999\n",
            "e 70 - Total L1 loss: 1.751999\n",
            "e 71 - Total L1 loss: 1.751999\n",
            "e 72 - Total L1 loss: 1.751999\n",
            "e 73 - Total L1 loss: 1.751999\n",
            "e 74 - Total L1 loss: 1.751999\n",
            "e 75 - Total L1 loss: 1.751999\n",
            "e 76 - Total L1 loss: 1.751999\n",
            "e 77 - Total L1 loss: 1.751999\n",
            "e 78 - Total L1 loss: 1.751999\n",
            "e 79 - Total L1 loss: 1.751998\n",
            "e 80 - Total L1 loss: 1.751998\n",
            "e 81 - Total L1 loss: 1.751998\n",
            "e 82 - Total L1 loss: 1.751998\n",
            "e 83 - Total L1 loss: 1.751998\n",
            "e 84 - Total L1 loss: 1.751998\n",
            "e 85 - Total L1 loss: 1.751998\n",
            "e 86 - Total L1 loss: 1.751998\n",
            "e 87 - Total L1 loss: 1.751998\n",
            "e 88 - Total L1 loss: 1.751998\n",
            "e 89 - Total L1 loss: 1.751998\n",
            "e 90 - Total L1 loss: 1.751998\n",
            "e 91 - Total L1 loss: 1.751998\n",
            "e 92 - Total L1 loss: 1.751998\n",
            "e 93 - Total L1 loss: 1.751998\n",
            "e 94 - Total L1 loss: 1.751997\n",
            "e 95 - Total L1 loss: 1.751997\n",
            "e 96 - Total L1 loss: 1.751997\n",
            "e 97 - Total L1 loss: 1.751997\n",
            "e 98 - Total L1 loss: 1.751997\n",
            "e 99 - Total L1 loss: 1.751997\n",
            "e 100 - Total L1 loss: 1.751997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_savepath = '/content/drive/MyDrive/eg3d/weights.pt'\n",
        "torch.save(model.state_dict(),weights_savepath)"
      ],
      "metadata": {
        "id": "QK1_E9BEHOoN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}