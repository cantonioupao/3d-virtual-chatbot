{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voca.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cg_UkGTwJG_-",
        "5qw_1Qs4JXYm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VOCA\n",
        "VOCA is an audio driven, rig based speech avatar animation.The learned model, VOCA (Voice Operated Character Animation) takes any speech signal as input—even speech in languages other than English—and realistically animates a wide range of adult faces.It is rapidly applicable to even unseen targets.\n",
        "![](https://ps.is.mpg.de/uploads/publication/image/22550/voca.png)"
      ],
      "metadata": {
        "id": "EfYpOCl758qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check CUDA availability\n",
        "If there is no GPU available, then edit the notebook settings, to include a GPU"
      ],
      "metadata": {
        "id": "krT57ucl7LCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF_ci5eE7J_S",
        "outputId": "808433cc-4869-49cd-d8dc-20535f084e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VOCA Installation"
      ],
      "metadata": {
        "id": "MnXFWcLW58k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install MESH library (psbody)"
      ],
      "metadata": {
        "id": "1G0OlQ5Z62Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Install MESH library\n",
        "!pip3 install git+https://github.com/MPI-IS/mesh.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScNdJSqc0np3",
        "outputId": "c8f5037c-05b6-4674-a0db-15a29333f8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/MPI-IS/mesh.git\n",
            "  Cloning https://github.com/MPI-IS/mesh.git to /tmp/pip-req-build-l35y7z3m\n",
            "  Running command git clone -q https://github.com/MPI-IS/mesh.git /tmp/pip-req-build-l35y7z3m\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (1.21.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (4.1.2.30)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (7.1.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (3.13)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (22.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from psbody-mesh==0.4) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VOCA requirements"
      ],
      "metadata": {
        "id": "xFGoeaiX66IF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbr29gM44pVX",
        "outputId": "3e1c66bd-2a71-409c-f57a-94b7b4a2a387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "fatal: destination path 'voca' already exists and is not an empty directory.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: chumpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.70)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.1.2.30)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.2.2)\n",
            "Requirement already satisfied: python-speech-features in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.6)\n",
            "Requirement already satisfied: tensorflow-gpu==1.15.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.0.2)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.5.33)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (3.10.8)\n",
            "Requirement already satisfied: pyrender in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.1.45)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.44.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.1.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (4.1.1)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy->-r requirements.txt (line 5)) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy->-r requirements.txt (line 5)) (0.34.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.7/dist-packages (from image->-r requirements.txt (line 9)) (3.2.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from image->-r requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r requirements.txt (line 10)) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: freetype-py in /usr/local/lib/python3.7/dist-packages (from pyrender->-r requirements.txt (line 13)) (2.2.0)\n",
            "Requirement already satisfied: PyOpenGL==3.1.0 in /usr/local/lib/python3.7/dist-packages (from pyrender->-r requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pyrender->-r requirements.txt (line 13)) (2.6.3)\n",
            "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.7/dist-packages (from pyrender->-r requirements.txt (line 13)) (1.5.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from pyrender->-r requirements.txt (line 13)) (2.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet>=1.4.10->pyrender->-r requirements.txt (line 13)) (0.16.0)\n",
            "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from django->image->-r requirements.txt (line 9)) (0.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from django->image->-r requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: asgiref<4,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from django->image->-r requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2->-r requirements.txt (line 7)) (1.5.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 10)) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "### VOCA requirements\n",
        "%cd /content/\n",
        "!sudo apt install ffmpeg\n",
        "!git clone https://github.com/TimoBolkart/voca.git\n",
        "#!pip install tensorboard==1.15\n",
        "#!pip install gast==0.3.2\n",
        "!cd voca && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data and models for VOCA demo\n",
        "All the models and data are stored in the Google Drive of each user, under the folder **/content/drive/MyDrive/voca/**"
      ],
      "metadata": {
        "id": "eMWKLrBwd-dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "### Download all data for VOCA demo\n",
        "from urllib import request\n",
        "import os\n",
        "\n",
        "#### Get VOCA account credentials first\n",
        "# to get the credentials please register and confirm your account in the following\n",
        "# websites :\n",
        "'https://voca.is.tue.mpg.de/register.php'\n",
        "'https://flame.is.tue.mpg.de/register.php'\n",
        "username = 'cantoniou@student.ethz.ch' #\"Add your username\"\n",
        "password = 'Poseidonos201!' #\"Add your password\"\n",
        "\n",
        "\n",
        "#### Define path\n",
        "voca_model_url = 'https://download.is.tue.mpg.de/download.php?domain=voca&resume=1&sfile=model.zip'\n",
        "voca_audio_sequences_url = 'https://download.is.tue.mpg.de/download.php?domain=voca&resume=1&sfile=audio.zip'\n",
        "template_meshes_url = 'https://download.is.tue.mpg.de/download.php?domain=voca&resume=1&sfile=templates.zip'\n",
        "flame_mpi_url = 'https://download.is.tue.mpg.de/download.php?domain=flame&resume=1&sfile=FLAME2020.zip'\n",
        "deep_speech_url = 'https://github.com/mozilla/DeepSpeech/releases/download/v0.1.0/deepspeech-0.1.0-models.tar.gz'\n",
        "\n",
        "#### Download zip files\n",
        "cmd = \"!wget --user=%s --password=%s %s && \\\n",
        "      !wget --user=%s --password=%s %s && \\\n",
        "      !wget --user=%s --password=%s %s && \\\n",
        "      !wget --user=%s --password=%s %s  \\\n",
        "      !wget %s \" % (username, password, voca_model_url,\n",
        "                                           username, password,voca_audio_sequences_url,\n",
        "                                            username, password, template_meshes_url,\n",
        "                                            username, password, flame_mpi_url,\n",
        "                                            deep_speech_url )\n",
        "\n",
        "cmd = \"!wget %s \" % (deep_speech_url)\n",
        "os.system(cmd)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "XqhkTjUyBwD9",
        "outputId": "193a0efd-81d0-4790-ab85-71ec2c82082e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n### Download all data for VOCA demo\\nfrom urllib import request\\nimport os\\n\\n#### Get VOCA account credentials first\\n# to get the credentials please register and confirm your account in the following\\n# websites :\\n\\'https://voca.is.tue.mpg.de/register.php\\'\\n\\'https://flame.is.tue.mpg.de/register.php\\'\\nusername = \\'cantoniou@student.ethz.ch\\' #\"Add your username\"\\npassword = \\'Poseidonos201!\\' #\"Add your password\"\\n\\n\\n#### Define path\\nvoca_model_url = \\'https://download.is.tue.mpg.de/download.php?domain=voca&resume=1&sfile=model.zip\\'\\nvoca_audio_sequences_url = \\'https://download.is.tue.mpg.de/download.php?domain=voca&resume=1&sfile=audio.zip\\'\\ntemplate_meshes_url = \\'https://download.is.tue.mpg.de/download.php?domain=voca&resume=1&sfile=templates.zip\\'\\nflame_mpi_url = \\'https://download.is.tue.mpg.de/download.php?domain=flame&resume=1&sfile=FLAME2020.zip\\'\\ndeep_speech_url = \\'https://github.com/mozilla/DeepSpeech/releases/download/v0.1.0/deepspeech-0.1.0-models.tar.gz\\'\\n\\n#### Download zip files\\ncmd = \"!wget --user=%s --password=%s %s &&       !wget --user=%s --password=%s %s &&       !wget --user=%s --password=%s %s &&       !wget --user=%s --password=%s %s        !wget %s \" % (username, password, voca_model_url,\\n                                           username, password,voca_audio_sequences_url,\\n                                            username, password, template_meshes_url,\\n                                            username, password, flame_mpi_url,\\n                                            deep_speech_url )\\n\\ncmd = \"!wget %s \" % (deep_speech_url)\\nos.system(cmd)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget 'https://github.com/mozilla/DeepSpeech/releases/download/v0.1.0/deepspeech-0.1.0-models.tar.gz' -o /content/drive/MyDrive/voca/"
      ],
      "metadata": {
        "id": "GqnzwEo-Dvet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Place data & models to appropriate location"
      ],
      "metadata": {
        "id": "fHDfHigX78pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Setup files and place them to appropriate location\n",
        "!unzip /content/drive/MyDrive/voca/model.zip -d /content/voca/model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uClLxcEljKJJ",
        "outputId": "e7ce6c54-7c7d-4275-8759-da4d8b3ad012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/voca/model.zip\n",
            "  inflating: /content/voca/model/gstep_52280.model.data-00000-of-00001  \n",
            "  inflating: /content/voca/model/gstep_52280.model.index  \n",
            "  inflating: /content/voca/model/gstep_52280.model.meta  \n",
            "  inflating: /content/voca/model/readme.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip and place FLAME MODEL to appropriate folder\n",
        "!unzip /content/drive/MyDrive/voca/FLAME2020.zip -d /content/voca/flame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgt8PDUa7gvu",
        "outputId": "6a0d6d5f-d967-4cb9-a908-22914227114d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/voca/FLAME2020.zip\n",
            "  inflating: /content/voca/flame/female_model.pkl  \n",
            "  inflating: /content/voca/flame/generic_model.pkl  \n",
            "  inflating: /content/voca/flame/male_model.pkl  \n",
            "  inflating: /content/voca/flame/Readme.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip and place audio sequences to audio folder\n",
        "!unzip /content/drive/MyDrive/voca/audio.zip -d /content/voca/audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c-epr1r8D3R",
        "outputId": "433354f2-74cb-49da-edd4-aa2b95b955fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/voca/audio.zip\n",
            "   creating: /content/voca/audio/FaceTalk_170725_00137_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170725_00137_TA/sentence19.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170728_03272_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170728_03272_TA/sentence22.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170731_00024_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170731_00024_TA/sentence34.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170809_00138_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170809_00138_TA/sentence23.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170811_03274_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03274_TA/sentence01.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170811_03275_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170811_03275_TA/sentence18.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170904_00128_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_00128_TA/sentence23.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170904_03276_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170904_03276_TA/sentence03.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170908_03277_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170908_03277_TA/sentence14.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170912_03278_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170912_03278_TA/sentence33.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170913_03279_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170913_03279_TA/sentence05.wav  \n",
            "   creating: /content/voca/audio/FaceTalk_170915_00223_TA/\n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence32.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence02.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence16.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence17.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence24.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence28.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence07.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence06.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence01.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence36.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence26.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence15.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence23.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence11.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence22.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence27.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence38.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence03.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence34.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence19.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence30.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence05.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence39.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence33.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence13.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence37.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence21.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence12.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence09.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence04.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence10.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence31.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence20.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence35.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence08.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence18.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence14.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence29.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence25.wav  \n",
            "  inflating: /content/voca/audio/FaceTalk_170915_00223_TA/sentence40.wav  \n",
            "  inflating: /content/voca/audio/readme.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip and place templates to template folder\n",
        "!unzip /content/drive/MyDrive/voca/templates.zip -d /content/voca/template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bNfE7Vn8FmX",
        "outputId": "40e58ea6-b258-47f2-80af-4e0c44db2a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/voca/templates.zip\n",
            "  inflating: /content/voca/template/FaceTalk_170725_00137_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170728_03272_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170731_00024_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170809_00138_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170811_03274_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170811_03275_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170904_00128_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170904_03276_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170908_03277_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170912_03278_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170913_03279_TA.ply  \n",
            "  inflating: /content/voca/template/FaceTalk_170915_00223_TA.ply  \n",
            "  inflating: /content/voca/template/readme.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Unzip deep speech model and palce in ds_graph folder\n",
        "!tar -xvf /content/drive/MyDrive/voca/deepspeech-0.1.0-models.tar.gz  -C /content/voca/ds_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh_Qxyt08nYb",
        "outputId": "cedd2b71-6c76-4800-f918-33ff86843922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/\n",
            "models/lm.binary\n",
            "models/output_graph.pb\n",
            "models/trie\n",
            "models/alphabet.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VOCA demo\n",
        "This demo runs VOCA, which outputs the animation meshes given audio sequences, and renders the animation sequence to a video.\n",
        "To succesfully run the demo (in case of error), deactivate visualization for Google Colab (remote environment) and save all meshes in folder. Then you can use an online 3D render to view them."
      ],
      "metadata": {
        "id": "cLpp29kohz9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disable Eager Execution "
      ],
      "metadata": {
        "id": "cg_UkGTwJG_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/voca/utils/inference.py\n",
        "'''\n",
        "Max-Planck-Gesellschaft zur Foerderung der Wissenschaften e.V. (MPG) is holder of all proprietary rights on this\n",
        "computer program.\n",
        "\n",
        "You can only use this computer program if you have closed a license agreement with MPG or you get the right to use\n",
        "the computer program from someone who is authorized to grant you that right.\n",
        "\n",
        "Any use of the computer program without a valid license is prohibited and liable to prosecution.\n",
        "\n",
        "Copyright 2019 Max-Planck-Gesellschaft zur Foerderung der Wissenschaften e.V. (MPG). acting on behalf of its\n",
        "Max Planck Institute for Intelligent Systems and the Max Planck Institute for Biological Cybernetics.\n",
        "All rights reserved.\n",
        "\n",
        "More information about VOCA is available at http://voca.is.tue.mpg.de.\n",
        "For comments or questions, please email us at voca@tue.mpg.de\n",
        "'''\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import scipy\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from subprocess import call\n",
        "from scipy.io import wavfile\n",
        "\n",
        "\n",
        "from psbody.mesh import Mesh\n",
        "from utils.audio_handler import  AudioHandler\n",
        "from utils.rendering import render_mesh_helper\n",
        "\n",
        "\n",
        "### Check if TF us running on eager execution and deactivate\n",
        "import tensorflow as tf\n",
        "if tf.executing_eagerly():\n",
        "  tf.compat.v1.disable_eager_execution() # set to False\n",
        "\n",
        "\n",
        "def process_audio(ds_path, audio, sample_rate):\n",
        "    config = {}\n",
        "    config['deepspeech_graph_fname'] = ds_path\n",
        "    config['audio_feature_type'] = 'deepspeech'\n",
        "    config['num_audio_features'] = 29\n",
        "\n",
        "    config['audio_window_size'] = 16\n",
        "    config['audio_window_stride'] = 1\n",
        "\n",
        "    tmp_audio = {'subj': {'seq': {'audio': audio, 'sample_rate': sample_rate}}}\n",
        "    audio_handler = AudioHandler(config)\n",
        "    return audio_handler.process(tmp_audio)['subj']['seq']['audio']\n",
        "\n",
        "\n",
        "def output_sequence_meshes(sequence_vertices, template, out_path, uv_template_fname='', texture_img_fname=''):\n",
        "    mesh_out_path = os.path.join(out_path, 'meshes')\n",
        "    if not os.path.exists(mesh_out_path):\n",
        "        os.makedirs(mesh_out_path)\n",
        "\n",
        "    if os.path.exists(uv_template_fname):\n",
        "        uv_template = Mesh(filename=uv_template_fname)\n",
        "        vt, ft = uv_template.vt, uv_template.ft\n",
        "    else:\n",
        "        vt, ft = None, None\n",
        "\n",
        "    num_frames = sequence_vertices.shape[0]\n",
        "    for i_frame in range(num_frames):\n",
        "        out_fname = os.path.join(mesh_out_path, '%05d.obj' % i_frame)\n",
        "        out_mesh = Mesh(sequence_vertices[i_frame], template.f)\n",
        "        if vt is not None and ft is not None:\n",
        "            out_mesh.vt, out_mesh.ft = vt, ft\n",
        "        if os.path.exists(texture_img_fname):\n",
        "            out_mesh.set_texture_image(texture_img_fname)\n",
        "        out_mesh.write_obj(out_fname)\n",
        "\n",
        "def render_sequence_meshes(audio_fname, sequence_vertices, template, out_path, uv_template_fname='', texture_img_fname=''):\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    tmp_video_file = tempfile.NamedTemporaryFile('w', suffix='.mp4', dir=out_path)\n",
        "    if int(cv2.__version__[0]) < 3:\n",
        "        writer = cv2.VideoWriter(tmp_video_file.name, cv2.cv.CV_FOURCC(*'mp4v'), 60, (800, 800), True)\n",
        "    else:\n",
        "        writer = cv2.VideoWriter(tmp_video_file.name, cv2.VideoWriter_fourcc(*'mp4v'), 60, (800, 800), True)\n",
        "\n",
        "    if os.path.exists(uv_template_fname) and os.path.exists(texture_img_fname):\n",
        "        uv_template = Mesh(filename=uv_template_fname)\n",
        "        vt, ft = uv_template.vt, uv_template.ft\n",
        "        tex_img = cv2.imread(texture_img_fname)[:,:,::-1]\n",
        "    else:\n",
        "        vt, ft = None, None\n",
        "        tex_img = None\n",
        "\n",
        "    num_frames = sequence_vertices.shape[0]\n",
        "    center = np.mean(sequence_vertices[0], axis=0)\n",
        "    for i_frame in range(num_frames):\n",
        "        render_mesh = Mesh(sequence_vertices[i_frame], template.f)\n",
        "        if vt is not None and ft is not None:\n",
        "            render_mesh.vt, render_mesh.ft = vt, ft\n",
        "        img = render_mesh_helper(render_mesh, center, tex_img=tex_img)\n",
        "        writer.write(img)\n",
        "    writer.release()\n",
        "\n",
        "    video_fname = os.path.join(out_path, 'video.mp4')\n",
        "    cmd = ('ffmpeg' + ' -i {0} -i {1} -vcodec h264 -ac 2 -channel_layout stereo -pix_fmt yuv420p {2}'.format(\n",
        "        audio_fname, tmp_video_file.name, video_fname)).split()\n",
        "    call(cmd)\n",
        "\n",
        "\n",
        "def inference(tf_model_fname, ds_fname, audio_fname, template_fname, condition_idx, out_path, render_sequence=True, uv_template_fname='', texture_img_fname=''):\n",
        "    template = Mesh(filename=template_fname)\n",
        "\n",
        "    sample_rate, audio = wavfile.read(audio_fname)\n",
        "    if audio.ndim != 1:\n",
        "        print('Audio has multiple channels, only first channel is considered')\n",
        "        audio = audio[:,0]\n",
        "\n",
        "    processed_audio = process_audio(ds_fname, audio, sample_rate)\n",
        "\n",
        "    # Load previously saved meta graph in the default graph\n",
        "    saver = tf.train.import_meta_graph(tf_model_fname + '.meta')\n",
        "    graph = tf.get_default_graph()\n",
        "\n",
        "    speech_features = graph.get_tensor_by_name(u'VOCA/Inputs_encoder/speech_features:0')\n",
        "    condition_subject_id = graph.get_tensor_by_name(u'VOCA/Inputs_encoder/condition_subject_id:0')\n",
        "    is_training = graph.get_tensor_by_name(u'VOCA/Inputs_encoder/is_training:0')\n",
        "    input_template = graph.get_tensor_by_name(u'VOCA/Inputs_decoder/template_placeholder:0')\n",
        "    output_decoder = graph.get_tensor_by_name(u'VOCA/output_decoder:0')\n",
        "\n",
        "    num_frames = processed_audio.shape[0]\n",
        "    feed_dict = {speech_features: np.expand_dims(np.stack(processed_audio), -1),\n",
        "                 condition_subject_id: np.repeat(condition_idx-1, num_frames),\n",
        "                 is_training: False,\n",
        "                 input_template: np.repeat(template.v[np.newaxis, :, :, np.newaxis], num_frames, axis=0)}\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        # Restore trained model\n",
        "        saver.restore(session, tf_model_fname)\n",
        "        predicted_vertices = np.squeeze(session.run(output_decoder, feed_dict))\n",
        "        output_sequence_meshes(predicted_vertices, template, out_path)\n",
        "        if(render_sequence):\n",
        "            render_sequence_meshes(audio_fname, predicted_vertices, template, out_path, uv_template_fname, texture_img_fname)\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "\n",
        "def inference_interpolate_styles(tf_model_fname, ds_fname, audio_fname, template_fname, condition_weights, out_path):\n",
        "    template = Mesh(filename=template_fname)\n",
        "\n",
        "    sample_rate, audio = wavfile.read(audio_fname)\n",
        "    if audio.ndim != 1:\n",
        "        print('Audio has multiple channels, only first channel is considered')\n",
        "        audio = audio[:, 0]\n",
        "\n",
        "    processed_audio = process_audio(ds_fname, audio, sample_rate)\n",
        "\n",
        "    # Load previously saved meta graph in the default graph\n",
        "    saver = tf.train.import_meta_graph(tf_model_fname + '.meta')\n",
        "    graph = tf.get_default_graph()\n",
        "\n",
        "    speech_features = graph.get_tensor_by_name(u'VOCA/Inputs_encoder/speech_features:0')\n",
        "    condition_subject_id = graph.get_tensor_by_name(u'VOCA/Inputs_encoder/condition_subject_id:0')\n",
        "    is_training = graph.get_tensor_by_name(u'VOCA/Inputs_encoder/is_training:0')\n",
        "    input_template = graph.get_tensor_by_name(u'VOCA/Inputs_decoder/template_placeholder:0')\n",
        "    output_decoder = graph.get_tensor_by_name(u'VOCA/output_decoder:0')\n",
        "\n",
        "    non_zeros = np.where(condition_weights > 0.0)[0]\n",
        "    condition_weights[non_zeros] /= sum(condition_weights[non_zeros])\n",
        "\n",
        "    num_frames = processed_audio.shape[0]\n",
        "    output_vertices = np.zeros((num_frames, template.v.shape[0], template.v.shape[1]))\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        # Restore trained model\n",
        "        saver.restore(session, tf_model_fname)\n",
        "\n",
        "        for condition_id in non_zeros:\n",
        "            feed_dict = {speech_features: np.expand_dims(np.stack(processed_audio), -1),\n",
        "                         condition_subject_id: np.repeat(condition_id, num_frames),\n",
        "                         is_training: False,\n",
        "                         input_template: np.repeat(template.v[np.newaxis, :, :, np.newaxis], num_frames, axis=0)}\n",
        "            predicted_vertices = np.squeeze(session.run(output_decoder, feed_dict))\n",
        "            output_vertices += condition_weights[condition_id] * predicted_vertices\n",
        "\n",
        "        output_sequence_meshes(output_vertices, template, out_path)"
      ],
      "metadata": {
        "id": "5u1jiMowFrGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177eedfc-68d1-4d0d-c5f6-25841046c0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/voca/utils/inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "5qw_1Qs4JXYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/voca/\n",
        "!python3 run_voca.py --tf_model_fname './model/gstep_52280.model' \\\n",
        "--ds_fname './ds_graph/models/output_graph.pb'  \\\n",
        "--audio_fname '/content/drive/MyDrive/voca/trifilo_varvato_k_oraio.wav' \\\n",
        "--template_fname './template/FLAME_sample.ply' --condition_idx 3  --out_path  '/content/drive/MyDrive/voca/animation_pao/'   # './animation_output' \\\n",
        "#--visualize False \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap4YV8fiiZco",
        "outputId": "45829c41-f560-4cbf-fede-2e02d3d528f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/voca\n",
            "Audio has multiple channels, only first channel is considered\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:97: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:100: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:110: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-04-19 12:01:59.034659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-19 12:01:59.051612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.052285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-19 12:01:59.052607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:01:59.053862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-04-19 12:01:59.054956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-04-19 12:01:59.055314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-04-19 12:01:59.056830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-04-19 12:01:59.057856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-04-19 12:01:59.061412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-19 12:01:59.061549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.062211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.062905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-19 12:01:59.063279: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-04-19 12:01:59.067987: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
            "2022-04-19 12:01:59.074952: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f0bcaee00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-19 12:01:59.074989: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-19 12:01:59.242371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.248550: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f0bcaf500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-19 12:01:59.248595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2022-04-19 12:01:59.248837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.249532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-19 12:01:59.249639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:01:59.249670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-04-19 12:01:59.249699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-04-19 12:01:59.249726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-04-19 12:01:59.249756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-04-19 12:01:59.249781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-04-19 12:01:59.249808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-19 12:01:59.249907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.250630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.251231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-19 12:01:59.251388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:01:59.252814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-19 12:01:59.252846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-19 12:01:59.252858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-19 12:01:59.252995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.253682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:01:59.254287: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-19 12:01:59.254336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "process audio: subj - seq\n",
            "2022-04-19 12:02:00.120962: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:02:00.199780: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:02:00.388405: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:02:00.458109: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:02:00.527057: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:02:09.251379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From /content/voca/utils/inference.py:120: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
            "\n",
            "2022-04-19 12:02:10.290492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:02:10.291090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-19 12:02:10.291196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:02:10.291225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-04-19 12:02:10.291266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-04-19 12:02:10.291291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-04-19 12:02:10.291319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-04-19 12:02:10.291340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-04-19 12:02:10.291362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-19 12:02:10.291456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:02:10.292008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:02:10.292487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-19 12:02:10.292526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-19 12:02:10.292539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-19 12:02:10.292551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-19 12:02:10.292650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:02:10.293182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:02:10.293669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2022-04-19 12:02:10.422272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mInput #0, wav, from '/content/drive/MyDrive/voca/trifilo_varvato_k_oraio.wav':\n",
            "  Duration: 00:00:08.28, bitrate: 1536 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
            "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/voca/animation_pao/tmpk_kqq7y1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.35.100\n",
            "  Duration: 00:00:08.28, start: 0.000000, bitrate: 3170 kb/s\n",
            "    Stream #1:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 800x800 [SAR 1:1 DAR 1:1], 3167 kb/s, 60 fps, 60 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mprofile High, level 3.2\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/drive/MyDrive/voca/animation_pao/video.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 800x800 [SAR 1:1 DAR 1:1], q=-1--1, 60 fps, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame=  497 fps= 66 q=-1.0 Lsize=     696kB time=00:00:08.27 bitrate= 689.1kbits/s speed= 1.1x    \n",
            "video:553kB audio:130kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.067837%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mframe I:2     Avg QP:23.00  size:  7414\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mframe P:165   Avg QP:23.89  size:  1266\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mframe B:330   Avg QP:23.57  size:  1035\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mconsecutive B-frames:  5.6% 14.1% 10.3% 70.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mmb I  I16..4: 22.8% 72.3%  4.9%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mmb P  I16..4:  1.8%  2.5%  0.0%  P16..4: 11.1%  1.3%  0.5%  0.0%  0.0%    skip:82.8%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mmb B  I16..4:  2.1%  2.1%  0.0%  B16..8: 10.8%  1.0%  0.1%  direct: 0.5%  skip:83.4%  L0:46.6% L1:52.8% BI: 0.6%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0m8x8 transform intra:54.7% inter:87.1%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mcoded y,uvDC,uvAC intra: 22.9% 0.0% 0.0% inter: 2.0% 0.0% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mi16 v,h,dc,p: 28% 23% 10% 40%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 31% 20% 40%  2%  1%  2%  1%  2%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 30% 20%  4%  3%  4%  6%  3%  4%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mi8c dc,h,v,p: 100%  0%  0%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mWeighted P-Frames: Y:2.4% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mref P L0: 48.5%  6.6% 32.9% 11.2%  0.8%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mref B L0: 66.6% 28.1%  5.3%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mref B L1: 90.5%  9.5%\n",
            "\u001b[1;36m[libx264 @ 0x55f5408ae800] \u001b[0mkb/s:545.82\n",
            "\u001b[1;36m[aac @ 0x55f5408af700] \u001b[0mQavg: 2427.690\n",
            "WARNING:tensorflow:From /content/voca/utils/inference.py:142: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run VOCA and visualize the meshes with a pre-defined texture (obtained by fitting FLAME to an image using TF_FLAME"
      ],
      "metadata": {
        "id": "uv81VYo9iaYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_voca.py --tf_model_fname './model/gstep_52280.model'  \\\n",
        "--ds_fname './ds_graph/models/output_graph.pb' --audio_fname './audio/test_sentence.wav'  \\\n",
        "--template_fname './template/FLAME_sample.ply' --condition_idx 3       \\\n",
        "--uv_template_fname './template/texture_mesh.obj' --texture_img_fname './template/texture_mesh.png'  \\\n",
        "--out_path './animation_pao_textured'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfPNIOYKhzBo",
        "outputId": "c001e6c6-8ce5-48c1-9448-3f12ab1c0962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:97: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:100: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/voca/utils/audio_handler.py:110: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-04-19 12:18:28.435044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-19 12:18:28.452083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.452720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-19 12:18:28.453054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:18:28.454372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-04-19 12:18:28.455512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-04-19 12:18:28.455913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-04-19 12:18:28.457382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-04-19 12:18:28.458418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-04-19 12:18:28.461757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-19 12:18:28.461914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.462546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.463071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-19 12:18:28.463466: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-04-19 12:18:28.468020: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
            "2022-04-19 12:18:28.474622: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564be90a6e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-19 12:18:28.474655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-19 12:18:28.643442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.648956: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564be90a7500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-19 12:18:28.649000: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2022-04-19 12:18:28.649231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.649827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-19 12:18:28.649934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:18:28.649962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-04-19 12:18:28.649993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-04-19 12:18:28.650015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-04-19 12:18:28.650036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-04-19 12:18:28.650061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-04-19 12:18:28.650086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-19 12:18:28.650173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.650798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.651335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-19 12:18:28.651418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:18:28.652713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-19 12:18:28.652746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-19 12:18:28.652761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-19 12:18:28.652896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.653547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:28.654086: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-19 12:18:28.654165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "process audio: subj - seq\n",
            "2022-04-19 12:18:29.349214: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:18:29.425469: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:18:29.616014: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:18:29.683885: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:18:29.752390: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 201326592 exceeds 10% of system memory.\n",
            "2022-04-19 12:18:38.567445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From /content/voca/utils/inference.py:120: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
            "\n",
            "2022-04-19 12:18:39.454337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:39.454941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-19 12:18:39.455043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-04-19 12:18:39.455071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-04-19 12:18:39.455095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-04-19 12:18:39.455119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-04-19 12:18:39.455142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-04-19 12:18:39.455163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-04-19 12:18:39.455186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-19 12:18:39.455303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:39.455875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:39.456389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-19 12:18:39.456429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-19 12:18:39.456443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-19 12:18:39.456453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-19 12:18:39.456559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:39.457091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-19 12:18:39.457583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2022-04-19 12:18:39.577438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './audio/test_sentence.wav':\n",
            "  Duration: 00:00:05.10, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22000 Hz, mono, s16, 352 kb/s\n",
            "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/content/voca/animation_pao_textured/tmpodwiq1p2.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.35.100\n",
            "  Duration: 00:00:05.10, start: 0.000000, bitrate: 2711 kb/s\n",
            "    Stream #1:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 800x800 [SAR 1:1 DAR 1:1], 2707 kb/s, 60 fps, 60 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mprofile High, level 3.2\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to './animation_pao_textured/video.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 800x800 [SAR 1:1 DAR 1:1], q=-1--1, 60 fps, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 22050 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame=  306 fps= 77 q=-1.0 Lsize=     355kB time=00:00:05.10 bitrate= 569.4kbits/s speed=1.28x    \n",
            "video:279kB audio:69kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.900377%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mframe I:2     Avg QP:20.80  size: 13228\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mframe P:106   Avg QP:24.37  size:  1684\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mframe B:198   Avg QP:24.41  size:   405\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mconsecutive B-frames:  9.2%  7.2% 19.6% 64.1%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mmb I  I16..4: 23.4% 71.0%  5.7%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mmb P  I16..4:  0.2%  1.1%  0.0%  P16..4: 12.8%  2.1%  1.1%  0.0%  0.0%    skip:82.6%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mmb B  I16..4:  0.2%  0.3%  0.0%  B16..8:  9.7%  0.2%  0.0%  direct: 0.0%  skip:89.6%  L0:48.1% L1:51.2% BI: 0.7%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0m8x8 transform intra:72.0% inter:77.6%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mcoded y,uvDC,uvAC intra: 25.2% 28.0% 2.7% inter: 1.4% 1.1% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mi16 v,h,dc,p: 63% 11% 13% 13%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 14% 50%  1%  2%  2%  1%  1%  1%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 25% 21%  5%  3%  4%  5%  3%  4%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mi8c dc,h,v,p: 67% 17% 14%  2%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mref P L0: 56.3% 12.3% 20.9% 10.5%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mref B L0: 67.3% 24.4%  8.3%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mref B L1: 86.0% 14.0%\n",
            "\u001b[1;36m[libx264 @ 0x5575dcbc5900] \u001b[0mkb/s:447.19\n",
            "\u001b[1;36m[aac @ 0x5575dcbc7700] \u001b[0mQavg: 59583.547\n",
            "WARNING:tensorflow:From /content/voca/utils/inference.py:142: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VOCA extension\n",
        "Use Deep Speech to convert a text to an audio signal. Then parse this signal to the VOCA model. Along with the audio signal, add another input which describes the emotinal state of the text (sentiment analysis). This input might require a retraining of the model or it can be used just as a baseline to produce a video animation of the speaking person. At this stage there will be lacking ofc some emotion or more realistic facial expression. Then this video can be used as a driver vido input for the fd_vid2vid, along with a synthetic face reference input from StyleGAN. \n",
        "\n",
        "Now there are 2 options:\n",
        " 1. Try to influence the motion and expressions of the face directly on an avatar level (driver video level)\n",
        " 2. Influence facial expressions by using the generated images from StyleGAN. This means that for each word, an image could be generated matching the sentimental nature of the text (reference level)\n",
        "\n",
        " Another option could be to jointly influence both???"
      ],
      "metadata": {
        "id": "5ty0Wmt_63Uw"
      }
    }
  ]
}